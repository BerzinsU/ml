{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ugis/anaconda3/envs/mlbook/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/ugis/anaconda3/envs/mlbook/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "he_init = tf.variance_scaling_initializer()\n",
    "\n",
    "def dnn(inputs, n_hidden_layers=5, n_neurons=100, name=None,\n",
    "        activation=tf.nn.elu, initializer=he_init):\n",
    "    with tf.variable_scope(name, \"dnn\"):\n",
    "        for layer in range(n_hidden_layers):\n",
    "            inputs = tf.layers.dense(inputs, n_neurons, activation=activation,\n",
    "                                     kernel_initializer=initializer,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28 # MNIST\n",
    "n_outputs = 5\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "dnn_outputs = dnn(X)\n",
    "\n",
    "logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train[y_train < 5]\n",
    "y_train1 = y_train[y_train < 5]\n",
    "X_valid1 = X_valid[y_valid < 5]\n",
    "y_valid1 = y_valid[y_valid < 5]\n",
    "X_test1 = X_test[y_test < 5]\n",
    "y_test1 = y_test[y_test < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.138786\tBest loss: 0.138786\tAccuracy: 95.66%\n",
      "1\tValidation loss: 0.073387\tBest loss: 0.073387\tAccuracy: 98.20%\n",
      "2\tValidation loss: 1.610470\tBest loss: 0.073387\tAccuracy: 24.04%\n",
      "3\tValidation loss: 1.515214\tBest loss: 0.073387\tAccuracy: 27.21%\n",
      "4\tValidation loss: 1.632640\tBest loss: 0.073387\tAccuracy: 22.01%\n",
      "5\tValidation loss: 1.723132\tBest loss: 0.073387\tAccuracy: 22.01%\n",
      "6\tValidation loss: 1.759777\tBest loss: 0.073387\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_0_to_4.ckpt\n",
      "Final test accuracy: 98.21%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 25\n",
    "\n",
    "max_checks_without_progress = 5\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train1))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train1) // batch_size):\n",
    "            X_batch, y_batch = X_train1[rnd_indices], y_train1[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid1, y: y_valid1})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = saver.save(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test1, y: y_test1})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "class DNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_hidden_layers=5, n_neurons=100, optimizer_class=tf.train.AdamOptimizer,\n",
    "                 learning_rate=0.01, batch_size=20, activation=tf.nn.elu, initializer=he_init,\n",
    "                 batch_norm_momentum=None, dropout_rate=None, random_state=None):\n",
    "        \"\"\"Initialize the DNNClassifier by simply storing all the hyperparameters.\"\"\"\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.activation = activation\n",
    "        self.initializer = initializer\n",
    "        self.batch_norm_momentum = batch_norm_momentum\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.random_state = random_state\n",
    "        self._session = None\n",
    "\n",
    "    def _dnn(self, inputs):\n",
    "        \"\"\"Build the hidden layers, with support for batch normalization and dropout.\"\"\"\n",
    "        for layer in range(self.n_hidden_layers):\n",
    "            if self.dropout_rate:\n",
    "                inputs = tf.layers.dropout(inputs, self.dropout_rate, training=self._training)\n",
    "            inputs = tf.layers.dense(inputs, self.n_neurons,\n",
    "                                     kernel_initializer=self.initializer,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "            if self.batch_norm_momentum:\n",
    "                inputs = tf.layers.batch_normalization(inputs, momentum=self.batch_norm_momentum,\n",
    "                                                       training=self._training)\n",
    "            inputs = self.activation(inputs, name=\"hidden%d_out\" % (layer + 1))\n",
    "        return inputs\n",
    "\n",
    "    def _build_graph(self, n_inputs, n_outputs):\n",
    "        \"\"\"Build the same model as earlier\"\"\"\n",
    "        if self.random_state is not None:\n",
    "            tf.set_random_seed(self.random_state)\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "        y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "        if self.batch_norm_momentum or self.dropout_rate:\n",
    "            self._training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "        else:\n",
    "            self._training = None\n",
    "\n",
    "        dnn_outputs = self._dnn(X)\n",
    "\n",
    "        logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "        Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                                  logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "        optimizer = self.optimizer_class(learning_rate=self.learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # Make the important operations available easily through instance variables\n",
    "        self._X, self._y = X, y\n",
    "        self._Y_proba, self._loss = Y_proba, loss\n",
    "        self._training_op, self._accuracy = training_op, accuracy\n",
    "        self._init, self._saver = init, saver\n",
    "\n",
    "    def close_session(self):\n",
    "        if self._session:\n",
    "            self._session.close()\n",
    "\n",
    "    def _get_model_params(self):\n",
    "        \"\"\"Get all variable values (used for early stopping, faster than saving to disk)\"\"\"\n",
    "        with self._graph.as_default():\n",
    "            gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        return {gvar.op.name: value for gvar, value in zip(gvars, self._session.run(gvars))}\n",
    "\n",
    "    def _restore_model_params(self, model_params):\n",
    "        \"\"\"Set all variables to the given values (for early stopping, faster than loading from disk)\"\"\"\n",
    "        gvar_names = list(model_params.keys())\n",
    "        assign_ops = {gvar_name: self._graph.get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                      for gvar_name in gvar_names}\n",
    "        init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "        feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "        self._session.run(assign_ops, feed_dict=feed_dict)\n",
    "\n",
    "    def fit(self, X, y, n_epochs=100, X_valid=None, y_valid=None):\n",
    "        \"\"\"Fit the model to the training set. If X_valid and y_valid are provided, use early stopping.\"\"\"\n",
    "        self.close_session()\n",
    "\n",
    "        # infer n_inputs and n_outputs from the training set.\n",
    "        n_inputs = X.shape[1]\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_outputs = len(self.classes_)\n",
    "        \n",
    "        # Translate the labels vector to a vector of sorted class indices, containing\n",
    "        # integers from 0 to n_outputs - 1.\n",
    "        # For example, if y is equal to [8, 8, 9, 5, 7, 6, 6, 6], then the sorted class\n",
    "        # labels (self.classes_) will be equal to [5, 6, 7, 8, 9], and the labels vector\n",
    "        # will be translated to [3, 3, 4, 0, 2, 1, 1, 1]\n",
    "        self.class_to_index_ = {label: index\n",
    "                                for index, label in enumerate(self.classes_)}\n",
    "        y = np.array([self.class_to_index_[label]\n",
    "                      for label in y], dtype=np.int32)\n",
    "        \n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "            self._build_graph(n_inputs, n_outputs)\n",
    "            # extra ops for batch normalization\n",
    "            extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "        # needed in case of early stopping\n",
    "        max_checks_without_progress = 5\n",
    "        checks_without_progress = 0\n",
    "        best_loss = np.infty\n",
    "        best_params = None\n",
    "        \n",
    "        # Now train the model!\n",
    "        self._session = tf.Session(graph=self._graph)\n",
    "        with self._session.as_default() as sess:\n",
    "            self._init.run()\n",
    "            for epoch in range(n_epochs):\n",
    "                rnd_idx = np.random.permutation(len(X))\n",
    "                for rnd_indices in np.array_split(rnd_idx, len(X) // self.batch_size):\n",
    "                    X_batch, y_batch = X[rnd_indices], y[rnd_indices]\n",
    "                    feed_dict = {self._X: X_batch, self._y: y_batch}\n",
    "                    if self._training is not None:\n",
    "                        feed_dict[self._training] = True\n",
    "                    sess.run(self._training_op, feed_dict=feed_dict)\n",
    "                    if extra_update_ops:\n",
    "                        sess.run(extra_update_ops, feed_dict=feed_dict)\n",
    "                if X_valid is not None and y_valid is not None:\n",
    "                    loss_val, acc_val = sess.run([self._loss, self._accuracy],\n",
    "                                                 feed_dict={self._X: X_valid,\n",
    "                                                            self._y: y_valid})\n",
    "                    if loss_val < best_loss:\n",
    "                        best_params = self._get_model_params()\n",
    "                        best_loss = loss_val\n",
    "                        checks_without_progress = 0\n",
    "                    else:\n",
    "                        checks_without_progress += 1\n",
    "                    print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                        epoch, loss_val, best_loss, acc_val * 100))\n",
    "                    if checks_without_progress > max_checks_without_progress:\n",
    "                        print(\"Early stopping!\")\n",
    "                        break\n",
    "                else:\n",
    "                    loss_train, acc_train = sess.run([self._loss, self._accuracy],\n",
    "                                                     feed_dict={self._X: X_batch,\n",
    "                                                                self._y: y_batch})\n",
    "                    print(\"{}\\tLast training batch loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                        epoch, loss_train, acc_train * 100))\n",
    "            # If we used early stopping then rollback to the best model found\n",
    "            if best_params:\n",
    "                self._restore_model_params(best_params)\n",
    "            return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not self._session:\n",
    "            raise NotFittedError(\"This %s instance is not fitted yet\" % self.__class__.__name__)\n",
    "        with self._session.as_default() as sess:\n",
    "            return self._Y_proba.eval(feed_dict={self._X: X})\n",
    "\n",
    "    def predict(self, X):\n",
    "        class_indices = np.argmax(self.predict_proba(X), axis=1)\n",
    "        return np.array([[self.classes_[class_index]]\n",
    "                         for class_index in class_indices], np.int32)\n",
    "\n",
    "    def save(self, path):\n",
    "        self._saver.save(self._session, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.116407\tBest loss: 0.116407\tAccuracy: 97.58%\n",
      "1\tValidation loss: 0.180534\tBest loss: 0.116407\tAccuracy: 97.11%\n",
      "2\tValidation loss: 0.227535\tBest loss: 0.116407\tAccuracy: 93.86%\n",
      "3\tValidation loss: 0.107346\tBest loss: 0.107346\tAccuracy: 97.54%\n",
      "4\tValidation loss: 0.302668\tBest loss: 0.107346\tAccuracy: 95.35%\n",
      "5\tValidation loss: 1.631054\tBest loss: 0.107346\tAccuracy: 22.01%\n",
      "6\tValidation loss: 1.635262\tBest loss: 0.107346\tAccuracy: 18.73%\n",
      "7\tValidation loss: 1.671200\tBest loss: 0.107346\tAccuracy: 22.01%\n",
      "8\tValidation loss: 1.695277\tBest loss: 0.107346\tAccuracy: 19.27%\n",
      "9\tValidation loss: 1.744607\tBest loss: 0.107346\tAccuracy: 20.91%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function elu at 0x11d853730>,\n",
       "       batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
       "       initializer=<tensorflow.python.ops.init_ops.VarianceScaling object at 0x112ea8fd0>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=100,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf = DNNClassifier(random_state=42)\n",
    "dnn_clf.fit(X_train1, y_train1, n_epochs=1000, X_valid=X_valid1, y_valid=y_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9725627553998832"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = dnn_clf.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=120 \n",
      "0\tValidation loss: 0.102654\tBest loss: 0.102654\tAccuracy: 96.83%\n",
      "1\tValidation loss: 0.067470\tBest loss: 0.067470\tAccuracy: 97.62%\n",
      "2\tValidation loss: 0.075195\tBest loss: 0.067470\tAccuracy: 97.62%\n",
      "3\tValidation loss: 0.050504\tBest loss: 0.050504\tAccuracy: 98.32%\n",
      "4\tValidation loss: 0.051863\tBest loss: 0.050504\tAccuracy: 98.63%\n",
      "5\tValidation loss: 0.066369\tBest loss: 0.050504\tAccuracy: 98.20%\n",
      "6\tValidation loss: 0.052643\tBest loss: 0.050504\tAccuracy: 98.51%\n",
      "7\tValidation loss: 0.081000\tBest loss: 0.050504\tAccuracy: 98.12%\n",
      "8\tValidation loss: 0.053567\tBest loss: 0.050504\tAccuracy: 98.48%\n",
      "9\tValidation loss: 0.066718\tBest loss: 0.050504\tAccuracy: 98.28%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=120, total=   3.0s\n",
      "[CV] learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=120 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.103043\tBest loss: 0.103043\tAccuracy: 96.40%\n",
      "1\tValidation loss: 0.077100\tBest loss: 0.077100\tAccuracy: 97.58%\n",
      "2\tValidation loss: 0.059739\tBest loss: 0.059739\tAccuracy: 98.01%\n",
      "3\tValidation loss: 0.060587\tBest loss: 0.059739\tAccuracy: 98.16%\n",
      "4\tValidation loss: 0.060387\tBest loss: 0.059739\tAccuracy: 98.16%\n",
      "5\tValidation loss: 0.062347\tBest loss: 0.059739\tAccuracy: 97.93%\n",
      "6\tValidation loss: 0.051471\tBest loss: 0.051471\tAccuracy: 98.51%\n",
      "7\tValidation loss: 0.064002\tBest loss: 0.051471\tAccuracy: 98.40%\n",
      "8\tValidation loss: 0.054955\tBest loss: 0.051471\tAccuracy: 98.48%\n",
      "9\tValidation loss: 0.057585\tBest loss: 0.051471\tAccuracy: 98.59%\n",
      "10\tValidation loss: 0.057599\tBest loss: 0.051471\tAccuracy: 98.59%\n",
      "11\tValidation loss: 0.111087\tBest loss: 0.051471\tAccuracy: 97.85%\n",
      "12\tValidation loss: 0.061107\tBest loss: 0.051471\tAccuracy: 98.75%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=120, total=   3.7s\n",
      "[CV] learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=120 \n",
      "0\tValidation loss: 0.094534\tBest loss: 0.094534\tAccuracy: 96.95%\n",
      "1\tValidation loss: 0.067658\tBest loss: 0.067658\tAccuracy: 97.81%\n",
      "2\tValidation loss: 0.063297\tBest loss: 0.063297\tAccuracy: 98.12%\n",
      "3\tValidation loss: 0.064505\tBest loss: 0.063297\tAccuracy: 97.77%\n",
      "4\tValidation loss: 0.050985\tBest loss: 0.050985\tAccuracy: 98.44%\n",
      "5\tValidation loss: 0.051042\tBest loss: 0.050985\tAccuracy: 98.55%\n",
      "6\tValidation loss: 0.067381\tBest loss: 0.050985\tAccuracy: 97.81%\n",
      "7\tValidation loss: 0.048600\tBest loss: 0.048600\tAccuracy: 98.55%\n",
      "8\tValidation loss: 0.044154\tBest loss: 0.044154\tAccuracy: 98.67%\n",
      "9\tValidation loss: 0.058219\tBest loss: 0.044154\tAccuracy: 98.55%\n",
      "10\tValidation loss: 0.052019\tBest loss: 0.044154\tAccuracy: 98.51%\n",
      "11\tValidation loss: 0.048946\tBest loss: 0.044154\tAccuracy: 98.83%\n",
      "12\tValidation loss: 0.074658\tBest loss: 0.044154\tAccuracy: 98.24%\n",
      "13\tValidation loss: 0.045128\tBest loss: 0.044154\tAccuracy: 98.87%\n",
      "14\tValidation loss: 0.062102\tBest loss: 0.044154\tAccuracy: 98.83%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=120, total=   4.4s\n",
      "[CV] learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=140 \n",
      "0\tValidation loss: 0.118560\tBest loss: 0.118560\tAccuracy: 96.29%\n",
      "1\tValidation loss: 0.075129\tBest loss: 0.075129\tAccuracy: 97.58%\n",
      "2\tValidation loss: 0.075727\tBest loss: 0.075129\tAccuracy: 97.89%\n",
      "3\tValidation loss: 0.054027\tBest loss: 0.054027\tAccuracy: 98.28%\n",
      "4\tValidation loss: 0.059574\tBest loss: 0.054027\tAccuracy: 98.16%\n",
      "5\tValidation loss: 0.051408\tBest loss: 0.051408\tAccuracy: 98.48%\n",
      "6\tValidation loss: 0.056061\tBest loss: 0.051408\tAccuracy: 98.24%\n",
      "7\tValidation loss: 0.090701\tBest loss: 0.051408\tAccuracy: 97.65%\n",
      "8\tValidation loss: 0.061691\tBest loss: 0.051408\tAccuracy: 98.40%\n",
      "9\tValidation loss: 0.044844\tBest loss: 0.044844\tAccuracy: 98.83%\n",
      "10\tValidation loss: 0.055570\tBest loss: 0.044844\tAccuracy: 98.63%\n",
      "11\tValidation loss: 0.065119\tBest loss: 0.044844\tAccuracy: 98.51%\n",
      "12\tValidation loss: 0.069498\tBest loss: 0.044844\tAccuracy: 98.48%\n",
      "13\tValidation loss: 0.047282\tBest loss: 0.044844\tAccuracy: 98.79%\n",
      "14\tValidation loss: 0.048871\tBest loss: 0.044844\tAccuracy: 98.67%\n",
      "15\tValidation loss: 0.086901\tBest loss: 0.044844\tAccuracy: 98.40%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=140, total=   5.3s\n",
      "[CV] learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=140 \n",
      "0\tValidation loss: 0.114847\tBest loss: 0.114847\tAccuracy: 96.36%\n",
      "1\tValidation loss: 0.078867\tBest loss: 0.078867\tAccuracy: 97.54%\n",
      "2\tValidation loss: 0.061129\tBest loss: 0.061129\tAccuracy: 98.01%\n",
      "3\tValidation loss: 0.057092\tBest loss: 0.057092\tAccuracy: 98.20%\n",
      "4\tValidation loss: 0.071052\tBest loss: 0.057092\tAccuracy: 98.12%\n",
      "5\tValidation loss: 0.061770\tBest loss: 0.057092\tAccuracy: 98.36%\n",
      "6\tValidation loss: 0.053976\tBest loss: 0.053976\tAccuracy: 98.48%\n",
      "7\tValidation loss: 0.051956\tBest loss: 0.051956\tAccuracy: 98.67%\n",
      "8\tValidation loss: 0.050327\tBest loss: 0.050327\tAccuracy: 98.79%\n",
      "9\tValidation loss: 0.051348\tBest loss: 0.050327\tAccuracy: 98.91%\n",
      "10\tValidation loss: 0.069928\tBest loss: 0.050327\tAccuracy: 98.67%\n",
      "11\tValidation loss: 0.065949\tBest loss: 0.050327\tAccuracy: 98.40%\n",
      "12\tValidation loss: 0.060279\tBest loss: 0.050327\tAccuracy: 98.63%\n",
      "13\tValidation loss: 0.053988\tBest loss: 0.050327\tAccuracy: 98.75%\n",
      "14\tValidation loss: 0.080882\tBest loss: 0.050327\tAccuracy: 98.08%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=140, total=   5.4s\n",
      "[CV] learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=140 \n",
      "0\tValidation loss: 0.109622\tBest loss: 0.109622\tAccuracy: 96.44%\n",
      "1\tValidation loss: 0.075064\tBest loss: 0.075064\tAccuracy: 97.89%\n",
      "2\tValidation loss: 0.060386\tBest loss: 0.060386\tAccuracy: 98.32%\n",
      "3\tValidation loss: 0.062676\tBest loss: 0.060386\tAccuracy: 98.12%\n",
      "4\tValidation loss: 0.050514\tBest loss: 0.050514\tAccuracy: 98.44%\n",
      "5\tValidation loss: 0.057517\tBest loss: 0.050514\tAccuracy: 98.16%\n",
      "6\tValidation loss: 0.080754\tBest loss: 0.050514\tAccuracy: 97.89%\n",
      "7\tValidation loss: 0.068748\tBest loss: 0.050514\tAccuracy: 97.97%\n",
      "8\tValidation loss: 0.063148\tBest loss: 0.050514\tAccuracy: 98.20%\n",
      "9\tValidation loss: 0.056786\tBest loss: 0.050514\tAccuracy: 98.44%\n",
      "10\tValidation loss: 0.059381\tBest loss: 0.050514\tAccuracy: 98.44%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=140, total=   4.1s\n",
      "[CV] learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=160 \n",
      "0\tValidation loss: 0.136784\tBest loss: 0.136784\tAccuracy: 95.50%\n",
      "1\tValidation loss: 0.081128\tBest loss: 0.081128\tAccuracy: 97.34%\n",
      "2\tValidation loss: 0.080647\tBest loss: 0.080647\tAccuracy: 97.46%\n",
      "3\tValidation loss: 0.060830\tBest loss: 0.060830\tAccuracy: 97.97%\n",
      "4\tValidation loss: 0.069861\tBest loss: 0.060830\tAccuracy: 98.16%\n",
      "5\tValidation loss: 0.063276\tBest loss: 0.060830\tAccuracy: 98.28%\n",
      "6\tValidation loss: 0.057150\tBest loss: 0.057150\tAccuracy: 98.44%\n",
      "7\tValidation loss: 0.061875\tBest loss: 0.057150\tAccuracy: 98.55%\n",
      "8\tValidation loss: 0.054644\tBest loss: 0.054644\tAccuracy: 98.48%\n",
      "9\tValidation loss: 0.054731\tBest loss: 0.054644\tAccuracy: 98.71%\n",
      "10\tValidation loss: 0.043088\tBest loss: 0.043088\tAccuracy: 98.91%\n",
      "11\tValidation loss: 0.062724\tBest loss: 0.043088\tAccuracy: 98.32%\n",
      "12\tValidation loss: 0.068621\tBest loss: 0.043088\tAccuracy: 98.24%\n",
      "13\tValidation loss: 0.054822\tBest loss: 0.043088\tAccuracy: 98.59%\n",
      "14\tValidation loss: 0.055556\tBest loss: 0.043088\tAccuracy: 98.71%\n",
      "15\tValidation loss: 0.047967\tBest loss: 0.043088\tAccuracy: 98.79%\n",
      "16\tValidation loss: 0.060030\tBest loss: 0.043088\tAccuracy: 98.75%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=160, total=   6.4s\n",
      "[CV] learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=160 \n",
      "0\tValidation loss: 0.116779\tBest loss: 0.116779\tAccuracy: 96.25%\n",
      "1\tValidation loss: 0.080192\tBest loss: 0.080192\tAccuracy: 97.46%\n",
      "2\tValidation loss: 0.063943\tBest loss: 0.063943\tAccuracy: 97.97%\n",
      "3\tValidation loss: 0.057310\tBest loss: 0.057310\tAccuracy: 98.20%\n",
      "4\tValidation loss: 0.071713\tBest loss: 0.057310\tAccuracy: 97.93%\n",
      "5\tValidation loss: 0.070477\tBest loss: 0.057310\tAccuracy: 98.16%\n",
      "6\tValidation loss: 0.075294\tBest loss: 0.057310\tAccuracy: 98.12%\n",
      "7\tValidation loss: 0.048907\tBest loss: 0.048907\tAccuracy: 98.79%\n",
      "8\tValidation loss: 0.075614\tBest loss: 0.048907\tAccuracy: 97.81%\n",
      "9\tValidation loss: 0.070339\tBest loss: 0.048907\tAccuracy: 98.40%\n",
      "10\tValidation loss: 0.044157\tBest loss: 0.044157\tAccuracy: 98.91%\n",
      "11\tValidation loss: 0.060407\tBest loss: 0.044157\tAccuracy: 98.63%\n",
      "12\tValidation loss: 0.073282\tBest loss: 0.044157\tAccuracy: 98.71%\n",
      "13\tValidation loss: 0.049262\tBest loss: 0.044157\tAccuracy: 98.79%\n",
      "14\tValidation loss: 0.069291\tBest loss: 0.044157\tAccuracy: 98.71%\n",
      "15\tValidation loss: 0.059774\tBest loss: 0.044157\tAccuracy: 98.87%\n",
      "16\tValidation loss: 0.061213\tBest loss: 0.044157\tAccuracy: 98.55%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=160, total=   7.2s\n",
      "[CV] learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=160 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.120318\tBest loss: 0.120318\tAccuracy: 96.01%\n",
      "1\tValidation loss: 0.087372\tBest loss: 0.087372\tAccuracy: 97.34%\n",
      "2\tValidation loss: 0.085191\tBest loss: 0.085191\tAccuracy: 97.38%\n",
      "3\tValidation loss: 0.064810\tBest loss: 0.064810\tAccuracy: 98.05%\n",
      "4\tValidation loss: 0.066227\tBest loss: 0.064810\tAccuracy: 98.16%\n",
      "5\tValidation loss: 0.048637\tBest loss: 0.048637\tAccuracy: 98.48%\n",
      "6\tValidation loss: 0.059078\tBest loss: 0.048637\tAccuracy: 98.44%\n",
      "7\tValidation loss: 0.053625\tBest loss: 0.048637\tAccuracy: 98.40%\n",
      "8\tValidation loss: 0.042102\tBest loss: 0.042102\tAccuracy: 98.87%\n",
      "9\tValidation loss: 0.047383\tBest loss: 0.042102\tAccuracy: 98.83%\n",
      "10\tValidation loss: 0.064882\tBest loss: 0.042102\tAccuracy: 98.55%\n",
      "11\tValidation loss: 0.063714\tBest loss: 0.042102\tAccuracy: 98.24%\n",
      "12\tValidation loss: 0.058097\tBest loss: 0.042102\tAccuracy: 98.59%\n",
      "13\tValidation loss: 0.052129\tBest loss: 0.042102\tAccuracy: 98.75%\n",
      "14\tValidation loss: 0.056399\tBest loss: 0.042102\tAccuracy: 98.67%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=350, activation=<function elu at 0x11d853730>, n_neurons=160, total=   6.3s\n",
      "[CV] learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=120 \n",
      "0\tValidation loss: 0.117795\tBest loss: 0.117795\tAccuracy: 96.40%\n",
      "1\tValidation loss: 0.079669\tBest loss: 0.079669\tAccuracy: 97.42%\n",
      "2\tValidation loss: 0.071660\tBest loss: 0.071660\tAccuracy: 97.69%\n",
      "3\tValidation loss: 0.060832\tBest loss: 0.060832\tAccuracy: 98.20%\n",
      "4\tValidation loss: 0.058978\tBest loss: 0.058978\tAccuracy: 98.05%\n",
      "5\tValidation loss: 0.053948\tBest loss: 0.053948\tAccuracy: 98.48%\n",
      "6\tValidation loss: 0.052217\tBest loss: 0.052217\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.051455\tBest loss: 0.051455\tAccuracy: 98.63%\n",
      "8\tValidation loss: 0.048415\tBest loss: 0.048415\tAccuracy: 98.63%\n",
      "9\tValidation loss: 0.051881\tBest loss: 0.048415\tAccuracy: 98.67%\n",
      "10\tValidation loss: 0.071889\tBest loss: 0.048415\tAccuracy: 98.44%\n",
      "11\tValidation loss: 0.077171\tBest loss: 0.048415\tAccuracy: 97.97%\n",
      "12\tValidation loss: 0.058452\tBest loss: 0.048415\tAccuracy: 98.48%\n",
      "13\tValidation loss: 0.061973\tBest loss: 0.048415\tAccuracy: 98.48%\n",
      "14\tValidation loss: 0.058122\tBest loss: 0.048415\tAccuracy: 98.51%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=120, total=   4.6s\n",
      "[CV] learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=120 \n",
      "0\tValidation loss: 0.104401\tBest loss: 0.104401\tAccuracy: 96.56%\n",
      "1\tValidation loss: 0.072429\tBest loss: 0.072429\tAccuracy: 97.62%\n",
      "2\tValidation loss: 0.063044\tBest loss: 0.063044\tAccuracy: 97.89%\n",
      "3\tValidation loss: 0.064294\tBest loss: 0.063044\tAccuracy: 98.48%\n",
      "4\tValidation loss: 0.067172\tBest loss: 0.063044\tAccuracy: 98.08%\n",
      "5\tValidation loss: 0.066352\tBest loss: 0.063044\tAccuracy: 97.46%\n",
      "6\tValidation loss: 0.052454\tBest loss: 0.052454\tAccuracy: 98.28%\n",
      "7\tValidation loss: 0.061528\tBest loss: 0.052454\tAccuracy: 98.36%\n",
      "8\tValidation loss: 0.047186\tBest loss: 0.047186\tAccuracy: 98.71%\n",
      "9\tValidation loss: 0.086352\tBest loss: 0.047186\tAccuracy: 97.89%\n",
      "10\tValidation loss: 0.067501\tBest loss: 0.047186\tAccuracy: 98.44%\n",
      "11\tValidation loss: 0.058013\tBest loss: 0.047186\tAccuracy: 98.51%\n",
      "12\tValidation loss: 0.042753\tBest loss: 0.042753\tAccuracy: 98.94%\n",
      "13\tValidation loss: 0.070359\tBest loss: 0.042753\tAccuracy: 98.48%\n",
      "14\tValidation loss: 0.052441\tBest loss: 0.042753\tAccuracy: 98.79%\n",
      "15\tValidation loss: 0.063417\tBest loss: 0.042753\tAccuracy: 98.75%\n",
      "16\tValidation loss: 0.072463\tBest loss: 0.042753\tAccuracy: 98.59%\n",
      "17\tValidation loss: 0.069310\tBest loss: 0.042753\tAccuracy: 98.36%\n",
      "18\tValidation loss: 0.056834\tBest loss: 0.042753\tAccuracy: 98.67%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=120, total=   5.6s\n",
      "[CV] learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=120 \n",
      "0\tValidation loss: 0.097564\tBest loss: 0.097564\tAccuracy: 96.87%\n",
      "1\tValidation loss: 0.073492\tBest loss: 0.073492\tAccuracy: 97.73%\n",
      "2\tValidation loss: 0.079222\tBest loss: 0.073492\tAccuracy: 97.46%\n",
      "3\tValidation loss: 0.058126\tBest loss: 0.058126\tAccuracy: 98.08%\n",
      "4\tValidation loss: 0.047002\tBest loss: 0.047002\tAccuracy: 98.59%\n",
      "5\tValidation loss: 0.048866\tBest loss: 0.047002\tAccuracy: 98.71%\n",
      "6\tValidation loss: 0.066488\tBest loss: 0.047002\tAccuracy: 98.24%\n",
      "7\tValidation loss: 0.046134\tBest loss: 0.046134\tAccuracy: 98.59%\n",
      "8\tValidation loss: 0.074658\tBest loss: 0.046134\tAccuracy: 98.08%\n",
      "9\tValidation loss: 0.053921\tBest loss: 0.046134\tAccuracy: 98.63%\n",
      "10\tValidation loss: 0.055996\tBest loss: 0.046134\tAccuracy: 98.75%\n",
      "11\tValidation loss: 0.065960\tBest loss: 0.046134\tAccuracy: 98.16%\n",
      "12\tValidation loss: 0.061007\tBest loss: 0.046134\tAccuracy: 98.79%\n",
      "13\tValidation loss: 0.050367\tBest loss: 0.046134\tAccuracy: 98.83%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=120, total=   4.3s\n",
      "[CV] learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=140 \n",
      "0\tValidation loss: 0.121091\tBest loss: 0.121091\tAccuracy: 96.21%\n",
      "1\tValidation loss: 0.074804\tBest loss: 0.074804\tAccuracy: 97.46%\n",
      "2\tValidation loss: 0.071039\tBest loss: 0.071039\tAccuracy: 97.93%\n",
      "3\tValidation loss: 0.064517\tBest loss: 0.064517\tAccuracy: 97.73%\n",
      "4\tValidation loss: 0.080012\tBest loss: 0.064517\tAccuracy: 97.62%\n",
      "5\tValidation loss: 0.051010\tBest loss: 0.051010\tAccuracy: 98.48%\n",
      "6\tValidation loss: 0.067061\tBest loss: 0.051010\tAccuracy: 97.93%\n",
      "7\tValidation loss: 0.063607\tBest loss: 0.051010\tAccuracy: 98.24%\n",
      "8\tValidation loss: 0.050977\tBest loss: 0.050977\tAccuracy: 98.87%\n",
      "9\tValidation loss: 0.049740\tBest loss: 0.049740\tAccuracy: 98.71%\n",
      "10\tValidation loss: 0.054990\tBest loss: 0.049740\tAccuracy: 98.71%\n",
      "11\tValidation loss: 0.057069\tBest loss: 0.049740\tAccuracy: 98.83%\n",
      "12\tValidation loss: 0.050485\tBest loss: 0.049740\tAccuracy: 98.87%\n",
      "13\tValidation loss: 0.046806\tBest loss: 0.046806\tAccuracy: 98.75%\n",
      "14\tValidation loss: 0.045061\tBest loss: 0.045061\tAccuracy: 99.10%\n",
      "15\tValidation loss: 0.077712\tBest loss: 0.045061\tAccuracy: 98.40%\n",
      "16\tValidation loss: 0.058488\tBest loss: 0.045061\tAccuracy: 98.79%\n",
      "17\tValidation loss: 0.042825\tBest loss: 0.042825\tAccuracy: 99.10%\n",
      "18\tValidation loss: 0.072278\tBest loss: 0.042825\tAccuracy: 98.71%\n",
      "19\tValidation loss: 0.062134\tBest loss: 0.042825\tAccuracy: 98.59%\n",
      "20\tValidation loss: 0.060667\tBest loss: 0.042825\tAccuracy: 98.71%\n",
      "21\tValidation loss: 0.048464\tBest loss: 0.042825\tAccuracy: 99.06%\n",
      "22\tValidation loss: 0.055488\tBest loss: 0.042825\tAccuracy: 99.18%\n",
      "23\tValidation loss: 0.079696\tBest loss: 0.042825\tAccuracy: 98.91%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=140, total=   8.4s\n",
      "[CV] learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=140 \n",
      "0\tValidation loss: 0.118409\tBest loss: 0.118409\tAccuracy: 96.40%\n",
      "1\tValidation loss: 0.072540\tBest loss: 0.072540\tAccuracy: 98.05%\n",
      "2\tValidation loss: 0.065221\tBest loss: 0.065221\tAccuracy: 97.77%\n",
      "3\tValidation loss: 0.059343\tBest loss: 0.059343\tAccuracy: 98.08%\n",
      "4\tValidation loss: 0.070032\tBest loss: 0.059343\tAccuracy: 98.05%\n",
      "5\tValidation loss: 0.057691\tBest loss: 0.057691\tAccuracy: 98.28%\n",
      "6\tValidation loss: 0.049646\tBest loss: 0.049646\tAccuracy: 98.71%\n",
      "7\tValidation loss: 0.063971\tBest loss: 0.049646\tAccuracy: 98.28%\n",
      "8\tValidation loss: 0.071343\tBest loss: 0.049646\tAccuracy: 98.28%\n",
      "9\tValidation loss: 0.068781\tBest loss: 0.049646\tAccuracy: 98.44%\n",
      "10\tValidation loss: 0.055120\tBest loss: 0.049646\tAccuracy: 98.20%\n",
      "11\tValidation loss: 0.066580\tBest loss: 0.049646\tAccuracy: 98.48%\n",
      "12\tValidation loss: 0.063839\tBest loss: 0.049646\tAccuracy: 98.63%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=140, total=   4.8s\n",
      "[CV] learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=140 \n",
      "0\tValidation loss: 0.104014\tBest loss: 0.104014\tAccuracy: 96.87%\n",
      "1\tValidation loss: 0.082610\tBest loss: 0.082610\tAccuracy: 97.69%\n",
      "2\tValidation loss: 0.075129\tBest loss: 0.075129\tAccuracy: 97.54%\n",
      "3\tValidation loss: 0.057759\tBest loss: 0.057759\tAccuracy: 98.32%\n",
      "4\tValidation loss: 0.065252\tBest loss: 0.057759\tAccuracy: 97.89%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\tValidation loss: 0.059148\tBest loss: 0.057759\tAccuracy: 98.51%\n",
      "6\tValidation loss: 0.067371\tBest loss: 0.057759\tAccuracy: 98.05%\n",
      "7\tValidation loss: 0.065055\tBest loss: 0.057759\tAccuracy: 98.51%\n",
      "8\tValidation loss: 0.052672\tBest loss: 0.052672\tAccuracy: 98.51%\n",
      "9\tValidation loss: 0.047913\tBest loss: 0.047913\tAccuracy: 98.75%\n",
      "10\tValidation loss: 0.057789\tBest loss: 0.047913\tAccuracy: 98.67%\n",
      "11\tValidation loss: 0.057472\tBest loss: 0.047913\tAccuracy: 98.87%\n",
      "12\tValidation loss: 0.059290\tBest loss: 0.047913\tAccuracy: 98.87%\n",
      "13\tValidation loss: 0.061347\tBest loss: 0.047913\tAccuracy: 98.75%\n",
      "14\tValidation loss: 0.051408\tBest loss: 0.047913\tAccuracy: 98.91%\n",
      "15\tValidation loss: 0.054068\tBest loss: 0.047913\tAccuracy: 98.94%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=140, total=   5.4s\n",
      "[CV] learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=160 \n",
      "0\tValidation loss: 0.154108\tBest loss: 0.154108\tAccuracy: 94.88%\n",
      "1\tValidation loss: 0.090532\tBest loss: 0.090532\tAccuracy: 96.91%\n",
      "2\tValidation loss: 0.079335\tBest loss: 0.079335\tAccuracy: 97.62%\n",
      "3\tValidation loss: 0.071108\tBest loss: 0.071108\tAccuracy: 97.81%\n",
      "4\tValidation loss: 0.071430\tBest loss: 0.071108\tAccuracy: 97.85%\n",
      "5\tValidation loss: 0.084540\tBest loss: 0.071108\tAccuracy: 97.89%\n",
      "6\tValidation loss: 0.046111\tBest loss: 0.046111\tAccuracy: 98.55%\n",
      "7\tValidation loss: 0.056002\tBest loss: 0.046111\tAccuracy: 98.48%\n",
      "8\tValidation loss: 0.056313\tBest loss: 0.046111\tAccuracy: 98.36%\n",
      "9\tValidation loss: 0.044125\tBest loss: 0.044125\tAccuracy: 98.51%\n",
      "10\tValidation loss: 0.044812\tBest loss: 0.044125\tAccuracy: 98.75%\n",
      "11\tValidation loss: 0.059781\tBest loss: 0.044125\tAccuracy: 98.67%\n",
      "12\tValidation loss: 0.045001\tBest loss: 0.044125\tAccuracy: 98.98%\n",
      "13\tValidation loss: 0.052235\tBest loss: 0.044125\tAccuracy: 98.75%\n",
      "14\tValidation loss: 0.056297\tBest loss: 0.044125\tAccuracy: 98.59%\n",
      "15\tValidation loss: 0.047323\tBest loss: 0.044125\tAccuracy: 98.94%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=160, total=   6.2s\n",
      "[CV] learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=160 \n",
      "0\tValidation loss: 0.115538\tBest loss: 0.115538\tAccuracy: 96.36%\n",
      "1\tValidation loss: 0.086986\tBest loss: 0.086986\tAccuracy: 97.50%\n",
      "2\tValidation loss: 0.074156\tBest loss: 0.074156\tAccuracy: 97.69%\n",
      "3\tValidation loss: 0.064724\tBest loss: 0.064724\tAccuracy: 97.97%\n",
      "4\tValidation loss: 0.082178\tBest loss: 0.064724\tAccuracy: 97.58%\n",
      "5\tValidation loss: 0.070782\tBest loss: 0.064724\tAccuracy: 97.93%\n",
      "6\tValidation loss: 0.054394\tBest loss: 0.054394\tAccuracy: 98.40%\n",
      "7\tValidation loss: 0.051809\tBest loss: 0.051809\tAccuracy: 98.55%\n",
      "8\tValidation loss: 0.057146\tBest loss: 0.051809\tAccuracy: 98.67%\n",
      "9\tValidation loss: 0.051191\tBest loss: 0.051191\tAccuracy: 98.59%\n",
      "10\tValidation loss: 0.064548\tBest loss: 0.051191\tAccuracy: 98.32%\n",
      "11\tValidation loss: 0.096809\tBest loss: 0.051191\tAccuracy: 97.93%\n",
      "12\tValidation loss: 0.060433\tBest loss: 0.051191\tAccuracy: 98.51%\n",
      "13\tValidation loss: 0.049477\tBest loss: 0.049477\tAccuracy: 98.79%\n",
      "14\tValidation loss: 0.072861\tBest loss: 0.049477\tAccuracy: 98.40%\n",
      "15\tValidation loss: 0.057402\tBest loss: 0.049477\tAccuracy: 98.55%\n",
      "16\tValidation loss: 0.099218\tBest loss: 0.049477\tAccuracy: 98.20%\n",
      "17\tValidation loss: 0.079208\tBest loss: 0.049477\tAccuracy: 98.55%\n",
      "18\tValidation loss: 0.083549\tBest loss: 0.049477\tAccuracy: 98.44%\n",
      "19\tValidation loss: 0.072083\tBest loss: 0.049477\tAccuracy: 98.59%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=160, total=   7.7s\n",
      "[CV] learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=160 \n",
      "0\tValidation loss: 0.114628\tBest loss: 0.114628\tAccuracy: 96.33%\n",
      "1\tValidation loss: 0.084849\tBest loss: 0.084849\tAccuracy: 97.15%\n",
      "2\tValidation loss: 0.072815\tBest loss: 0.072815\tAccuracy: 97.62%\n",
      "3\tValidation loss: 0.058605\tBest loss: 0.058605\tAccuracy: 98.36%\n",
      "4\tValidation loss: 0.055795\tBest loss: 0.055795\tAccuracy: 98.28%\n",
      "5\tValidation loss: 0.069057\tBest loss: 0.055795\tAccuracy: 98.16%\n",
      "6\tValidation loss: 0.063550\tBest loss: 0.055795\tAccuracy: 98.36%\n",
      "7\tValidation loss: 0.062170\tBest loss: 0.055795\tAccuracy: 98.16%\n",
      "8\tValidation loss: 0.050645\tBest loss: 0.050645\tAccuracy: 98.59%\n",
      "9\tValidation loss: 0.050905\tBest loss: 0.050645\tAccuracy: 98.51%\n",
      "10\tValidation loss: 0.056002\tBest loss: 0.050645\tAccuracy: 98.63%\n",
      "11\tValidation loss: 0.071868\tBest loss: 0.050645\tAccuracy: 98.40%\n",
      "12\tValidation loss: 0.088048\tBest loss: 0.050645\tAccuracy: 97.93%\n",
      "13\tValidation loss: 0.085757\tBest loss: 0.050645\tAccuracy: 98.51%\n",
      "14\tValidation loss: 0.056425\tBest loss: 0.050645\tAccuracy: 98.59%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=400, activation=<function elu at 0x11d853730>, n_neurons=160, total=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.076566\tBest loss: 0.076566\tAccuracy: 97.54%\n",
      "1\tValidation loss: 0.062139\tBest loss: 0.062139\tAccuracy: 98.01%\n",
      "2\tValidation loss: 0.049276\tBest loss: 0.049276\tAccuracy: 98.55%\n",
      "3\tValidation loss: 0.056261\tBest loss: 0.049276\tAccuracy: 98.32%\n",
      "4\tValidation loss: 0.033311\tBest loss: 0.033311\tAccuracy: 98.87%\n",
      "5\tValidation loss: 0.057880\tBest loss: 0.033311\tAccuracy: 98.48%\n",
      "6\tValidation loss: 0.035102\tBest loss: 0.033311\tAccuracy: 98.94%\n",
      "7\tValidation loss: 0.053952\tBest loss: 0.033311\tAccuracy: 98.63%\n",
      "8\tValidation loss: 0.043962\tBest loss: 0.033311\tAccuracy: 98.71%\n",
      "9\tValidation loss: 0.040287\tBest loss: 0.033311\tAccuracy: 98.94%\n",
      "10\tValidation loss: 0.045619\tBest loss: 0.033311\tAccuracy: 98.71%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=DNNClassifier(activation=<function elu at 0x11d853730>,\n",
       "       batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
       "       initializer=<tensorflow.python.ops.init_ops.VarianceScaling object at 0x112ea8fd0>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=100,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42),\n",
       "          fit_params=None, iid=True, n_iter=6, n_jobs=1,\n",
       "          param_distributions={'learning_rate': [0.01], 'batch_size': [350, 400], 'activation': [<function elu at 0x11d853730>], 'n_neurons': [120, 140, 160]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def leaky_relu(alpha=0.01):\n",
    "    def parametrized_leaky_relu(z, name=None):\n",
    "        return tf.maximum(alpha * z, z, name=name)\n",
    "    return parametrized_leaky_relu\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": [120, 140, 160],\n",
    "    \"batch_size\": [350,400],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"activation\": [tf.nn.elu],\n",
    "    # you could also try exploring different numbers of hidden layers, different optimizers, etc.\n",
    "    #\"n_hidden_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    #\"optimizer_class\": [tf.train.AdamOptimizer, partial(tf.train.MomentumOptimizer, momentum=0.95)],\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=6,\n",
    "                                random_state=42, verbose=2)\n",
    "rnd_search.fit(X_train1, y_train1, X_valid=X_valid1, y_valid=y_valid1, n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': <function tensorflow.python.ops.gen_nn_ops.elu>,\n",
       " 'batch_size': 400,\n",
       " 'learning_rate': 0.01,\n",
       " 'n_neurons': 140}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9902704806382565"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search.best_estimator_.save(\"./my_best_mnist_model_0_to_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.072285\tBest loss: 0.072285\tAccuracy: 97.73%\n",
      "1\tValidation loss: 0.055336\tBest loss: 0.055336\tAccuracy: 98.20%\n",
      "2\tValidation loss: 0.054911\tBest loss: 0.054911\tAccuracy: 98.55%\n",
      "3\tValidation loss: 0.072201\tBest loss: 0.054911\tAccuracy: 97.65%\n",
      "4\tValidation loss: 0.056247\tBest loss: 0.054911\tAccuracy: 98.32%\n",
      "5\tValidation loss: 0.045115\tBest loss: 0.045115\tAccuracy: 98.71%\n",
      "6\tValidation loss: 0.035851\tBest loss: 0.035851\tAccuracy: 99.10%\n",
      "7\tValidation loss: 22.659664\tBest loss: 0.035851\tAccuracy: 55.43%\n",
      "8\tValidation loss: 0.403495\tBest loss: 0.035851\tAccuracy: 96.99%\n",
      "9\tValidation loss: 0.126746\tBest loss: 0.035851\tAccuracy: 97.38%\n",
      "10\tValidation loss: 0.110300\tBest loss: 0.035851\tAccuracy: 97.54%\n",
      "11\tValidation loss: 0.089333\tBest loss: 0.035851\tAccuracy: 97.93%\n",
      "12\tValidation loss: 0.097720\tBest loss: 0.035851\tAccuracy: 97.58%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x182b2269d8>,\n",
       "       batch_norm_momentum=None, batch_size=400, dropout_rate=None,\n",
       "       initializer=<tensorflow.python.ops.init_ops.VarianceScaling object at 0x112ea8fd0>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=140,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf = DNNClassifier(activation=leaky_relu(alpha=0.1), batch_size=400, learning_rate=0.01,\n",
    "                        n_neurons=140, random_state=42)\n",
    "dnn_clf.fit(X_train1, y_train1, n_epochs=1000, X_valid=X_valid1, y_valid=y_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9910488421871959"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.046685\tBest loss: 0.046685\tAccuracy: 98.63%\n",
      "1\tValidation loss: 0.040820\tBest loss: 0.040820\tAccuracy: 98.79%\n",
      "2\tValidation loss: 0.046557\tBest loss: 0.040820\tAccuracy: 98.67%\n",
      "3\tValidation loss: 0.032236\tBest loss: 0.032236\tAccuracy: 98.94%\n",
      "4\tValidation loss: 0.056148\tBest loss: 0.032236\tAccuracy: 98.44%\n",
      "5\tValidation loss: 0.035988\tBest loss: 0.032236\tAccuracy: 98.98%\n",
      "6\tValidation loss: 0.037958\tBest loss: 0.032236\tAccuracy: 98.94%\n",
      "7\tValidation loss: 0.034588\tBest loss: 0.032236\tAccuracy: 99.02%\n",
      "8\tValidation loss: 0.031261\tBest loss: 0.031261\tAccuracy: 99.34%\n",
      "9\tValidation loss: 0.050791\tBest loss: 0.031261\tAccuracy: 98.79%\n",
      "10\tValidation loss: 0.035324\tBest loss: 0.031261\tAccuracy: 99.02%\n",
      "11\tValidation loss: 0.039875\tBest loss: 0.031261\tAccuracy: 98.98%\n",
      "12\tValidation loss: 0.048575\tBest loss: 0.031261\tAccuracy: 98.94%\n",
      "13\tValidation loss: 0.028059\tBest loss: 0.028059\tAccuracy: 99.18%\n",
      "14\tValidation loss: 0.044112\tBest loss: 0.028059\tAccuracy: 99.14%\n",
      "15\tValidation loss: 0.039050\tBest loss: 0.028059\tAccuracy: 99.22%\n",
      "16\tValidation loss: 0.033278\tBest loss: 0.028059\tAccuracy: 99.14%\n",
      "17\tValidation loss: 0.031734\tBest loss: 0.028059\tAccuracy: 99.18%\n",
      "18\tValidation loss: 0.034500\tBest loss: 0.028059\tAccuracy: 99.14%\n",
      "19\tValidation loss: 0.032757\tBest loss: 0.028059\tAccuracy: 99.26%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x182b3a5b70>,\n",
       "       batch_norm_momentum=0.95, batch_size=500, dropout_rate=None,\n",
       "       initializer=<tensorflow.python.ops.init_ops.VarianceScaling object at 0x112ea8fd0>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=90,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf_bn = DNNClassifier(activation=leaky_relu(alpha=0.1), batch_size=500, learning_rate=0.01,\n",
    "                           n_neurons=90, random_state=42,\n",
    "                           batch_norm_momentum=0.95)\n",
    "dnn_clf_bn.fit(X_train1, y_train1, n_epochs=1000, X_valid=X_valid1, y_valid=y_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9926055652850749"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf_bn.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ugis/anaconda3/envs/mlbook/lib/python3.5/site-packages/sklearn/model_selection/_search.py:584: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65 \n",
      "0\tValidation loss: 0.102916\tBest loss: 0.102916\tAccuracy: 97.22%\n",
      "1\tValidation loss: 0.068699\tBest loss: 0.068699\tAccuracy: 98.36%\n",
      "2\tValidation loss: 0.069956\tBest loss: 0.068699\tAccuracy: 98.24%\n",
      "3\tValidation loss: 0.041149\tBest loss: 0.041149\tAccuracy: 98.71%\n",
      "4\tValidation loss: 0.041666\tBest loss: 0.041149\tAccuracy: 98.87%\n",
      "5\tValidation loss: 0.059205\tBest loss: 0.041149\tAccuracy: 98.36%\n",
      "6\tValidation loss: 0.062153\tBest loss: 0.041149\tAccuracy: 98.20%\n",
      "7\tValidation loss: 0.051112\tBest loss: 0.041149\tAccuracy: 98.48%\n",
      "8\tValidation loss: 0.042609\tBest loss: 0.041149\tAccuracy: 98.91%\n",
      "9\tValidation loss: 0.076803\tBest loss: 0.041149\tAccuracy: 98.08%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65, total=  17.8s\n",
      "[CV] learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   17.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.065157\tBest loss: 0.065157\tAccuracy: 98.20%\n",
      "1\tValidation loss: 0.066359\tBest loss: 0.065157\tAccuracy: 98.12%\n",
      "2\tValidation loss: 0.065199\tBest loss: 0.065157\tAccuracy: 98.01%\n",
      "3\tValidation loss: 0.049340\tBest loss: 0.049340\tAccuracy: 98.48%\n",
      "4\tValidation loss: 0.059891\tBest loss: 0.049340\tAccuracy: 97.93%\n",
      "5\tValidation loss: 0.055341\tBest loss: 0.049340\tAccuracy: 98.59%\n",
      "6\tValidation loss: 0.041715\tBest loss: 0.041715\tAccuracy: 98.75%\n",
      "7\tValidation loss: 0.051146\tBest loss: 0.041715\tAccuracy: 98.59%\n",
      "8\tValidation loss: 0.043225\tBest loss: 0.041715\tAccuracy: 98.87%\n",
      "9\tValidation loss: 0.044080\tBest loss: 0.041715\tAccuracy: 98.98%\n",
      "10\tValidation loss: 0.063841\tBest loss: 0.041715\tAccuracy: 98.55%\n",
      "11\tValidation loss: 0.052395\tBest loss: 0.041715\tAccuracy: 98.63%\n",
      "12\tValidation loss: 0.030233\tBest loss: 0.030233\tAccuracy: 99.06%\n",
      "13\tValidation loss: 0.040267\tBest loss: 0.030233\tAccuracy: 98.94%\n",
      "14\tValidation loss: 0.128069\tBest loss: 0.030233\tAccuracy: 97.03%\n",
      "15\tValidation loss: 0.050301\tBest loss: 0.030233\tAccuracy: 98.94%\n",
      "16\tValidation loss: 0.038070\tBest loss: 0.030233\tAccuracy: 98.94%\n",
      "17\tValidation loss: 0.068828\tBest loss: 0.030233\tAccuracy: 98.05%\n",
      "18\tValidation loss: 0.057944\tBest loss: 0.030233\tAccuracy: 98.40%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65, total=  31.2s\n",
      "[CV] learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65 \n",
      "0\tValidation loss: 0.108436\tBest loss: 0.108436\tAccuracy: 97.38%\n",
      "1\tValidation loss: 0.053551\tBest loss: 0.053551\tAccuracy: 98.20%\n",
      "2\tValidation loss: 0.065032\tBest loss: 0.053551\tAccuracy: 98.28%\n",
      "3\tValidation loss: 0.054490\tBest loss: 0.053551\tAccuracy: 98.44%\n",
      "4\tValidation loss: 0.059941\tBest loss: 0.053551\tAccuracy: 98.51%\n",
      "5\tValidation loss: 0.041821\tBest loss: 0.041821\tAccuracy: 98.67%\n",
      "6\tValidation loss: 0.049714\tBest loss: 0.041821\tAccuracy: 98.71%\n",
      "7\tValidation loss: 0.049322\tBest loss: 0.041821\tAccuracy: 98.51%\n",
      "8\tValidation loss: 0.043631\tBest loss: 0.041821\tAccuracy: 98.83%\n",
      "9\tValidation loss: 0.032482\tBest loss: 0.032482\tAccuracy: 98.87%\n",
      "10\tValidation loss: 0.041955\tBest loss: 0.032482\tAccuracy: 98.87%\n",
      "11\tValidation loss: 0.044250\tBest loss: 0.032482\tAccuracy: 98.83%\n",
      "12\tValidation loss: 0.072912\tBest loss: 0.032482\tAccuracy: 98.20%\n",
      "13\tValidation loss: 0.030964\tBest loss: 0.030964\tAccuracy: 99.06%\n",
      "14\tValidation loss: 0.044794\tBest loss: 0.030964\tAccuracy: 98.94%\n",
      "15\tValidation loss: 0.033675\tBest loss: 0.030964\tAccuracy: 99.14%\n",
      "16\tValidation loss: 0.031628\tBest loss: 0.030964\tAccuracy: 99.10%\n",
      "17\tValidation loss: 0.034133\tBest loss: 0.030964\tAccuracy: 99.18%\n",
      "18\tValidation loss: 0.039455\tBest loss: 0.030964\tAccuracy: 98.91%\n",
      "19\tValidation loss: 0.046930\tBest loss: 0.030964\tAccuracy: 98.98%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65, total=  30.7s\n",
      "[CV] learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70 \n",
      "0\tValidation loss: 0.077757\tBest loss: 0.077757\tAccuracy: 98.05%\n",
      "1\tValidation loss: 0.072824\tBest loss: 0.072824\tAccuracy: 98.05%\n",
      "2\tValidation loss: 0.075372\tBest loss: 0.072824\tAccuracy: 97.93%\n",
      "3\tValidation loss: 0.038585\tBest loss: 0.038585\tAccuracy: 98.75%\n",
      "4\tValidation loss: 0.045389\tBest loss: 0.038585\tAccuracy: 98.79%\n",
      "5\tValidation loss: 0.048211\tBest loss: 0.038585\tAccuracy: 98.48%\n",
      "6\tValidation loss: 0.038931\tBest loss: 0.038585\tAccuracy: 98.59%\n",
      "7\tValidation loss: 0.043393\tBest loss: 0.038585\tAccuracy: 98.75%\n",
      "8\tValidation loss: 0.047029\tBest loss: 0.038585\tAccuracy: 98.59%\n",
      "9\tValidation loss: 0.042898\tBest loss: 0.038585\tAccuracy: 98.71%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70, total=  16.8s\n",
      "[CV] learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70 \n",
      "0\tValidation loss: 0.112826\tBest loss: 0.112826\tAccuracy: 97.07%\n",
      "1\tValidation loss: 0.059608\tBest loss: 0.059608\tAccuracy: 98.08%\n",
      "2\tValidation loss: 0.052742\tBest loss: 0.052742\tAccuracy: 98.55%\n",
      "3\tValidation loss: 0.050310\tBest loss: 0.050310\tAccuracy: 98.55%\n",
      "4\tValidation loss: 0.041359\tBest loss: 0.041359\tAccuracy: 98.75%\n",
      "5\tValidation loss: 0.039687\tBest loss: 0.039687\tAccuracy: 98.79%\n",
      "6\tValidation loss: 0.033055\tBest loss: 0.033055\tAccuracy: 98.87%\n",
      "7\tValidation loss: 0.052699\tBest loss: 0.033055\tAccuracy: 98.75%\n",
      "8\tValidation loss: 0.048919\tBest loss: 0.033055\tAccuracy: 98.51%\n",
      "9\tValidation loss: 0.058241\tBest loss: 0.033055\tAccuracy: 98.36%\n",
      "10\tValidation loss: 0.040428\tBest loss: 0.033055\tAccuracy: 98.87%\n",
      "11\tValidation loss: 0.054121\tBest loss: 0.033055\tAccuracy: 98.67%\n",
      "12\tValidation loss: 0.040795\tBest loss: 0.033055\tAccuracy: 98.98%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70, total=  24.4s\n",
      "[CV] learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70 \n",
      "0\tValidation loss: 0.085425\tBest loss: 0.085425\tAccuracy: 97.93%\n",
      "1\tValidation loss: 0.093794\tBest loss: 0.085425\tAccuracy: 97.58%\n",
      "2\tValidation loss: 0.071562\tBest loss: 0.071562\tAccuracy: 98.01%\n",
      "3\tValidation loss: 0.043793\tBest loss: 0.043793\tAccuracy: 98.51%\n",
      "4\tValidation loss: 0.042696\tBest loss: 0.042696\tAccuracy: 98.98%\n",
      "5\tValidation loss: 0.034887\tBest loss: 0.034887\tAccuracy: 98.83%\n",
      "6\tValidation loss: 0.054692\tBest loss: 0.034887\tAccuracy: 98.40%\n",
      "7\tValidation loss: 0.046622\tBest loss: 0.034887\tAccuracy: 98.59%\n",
      "8\tValidation loss: 0.047254\tBest loss: 0.034887\tAccuracy: 98.55%\n",
      "9\tValidation loss: 0.059788\tBest loss: 0.034887\tAccuracy: 98.40%\n",
      "10\tValidation loss: 0.049466\tBest loss: 0.034887\tAccuracy: 98.75%\n",
      "11\tValidation loss: 0.043253\tBest loss: 0.034887\tAccuracy: 98.75%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70, total=  22.1s\n",
      "[CV] learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75 \n",
      "0\tValidation loss: 0.077196\tBest loss: 0.077196\tAccuracy: 97.89%\n",
      "1\tValidation loss: 0.065729\tBest loss: 0.065729\tAccuracy: 98.32%\n",
      "2\tValidation loss: 0.065032\tBest loss: 0.065032\tAccuracy: 98.36%\n",
      "3\tValidation loss: 0.046995\tBest loss: 0.046995\tAccuracy: 98.63%\n",
      "4\tValidation loss: 0.038214\tBest loss: 0.038214\tAccuracy: 98.79%\n",
      "5\tValidation loss: 0.049660\tBest loss: 0.038214\tAccuracy: 98.87%\n",
      "6\tValidation loss: 0.038739\tBest loss: 0.038214\tAccuracy: 98.83%\n",
      "7\tValidation loss: 0.052706\tBest loss: 0.038214\tAccuracy: 98.83%\n",
      "8\tValidation loss: 0.040668\tBest loss: 0.038214\tAccuracy: 98.91%\n",
      "9\tValidation loss: 0.041320\tBest loss: 0.038214\tAccuracy: 99.06%\n",
      "10\tValidation loss: 0.049772\tBest loss: 0.038214\tAccuracy: 98.98%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75, total=  20.2s\n",
      "[CV] learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75 \n",
      "0\tValidation loss: 0.178932\tBest loss: 0.178932\tAccuracy: 96.17%\n",
      "1\tValidation loss: 0.069186\tBest loss: 0.069186\tAccuracy: 98.16%\n",
      "2\tValidation loss: 0.066870\tBest loss: 0.066870\tAccuracy: 98.20%\n",
      "3\tValidation loss: 0.044584\tBest loss: 0.044584\tAccuracy: 98.63%\n",
      "4\tValidation loss: 0.058421\tBest loss: 0.044584\tAccuracy: 98.48%\n",
      "5\tValidation loss: 0.052443\tBest loss: 0.044584\tAccuracy: 98.51%\n",
      "6\tValidation loss: 0.046537\tBest loss: 0.044584\tAccuracy: 98.59%\n",
      "7\tValidation loss: 0.048647\tBest loss: 0.044584\tAccuracy: 98.55%\n",
      "8\tValidation loss: 0.074047\tBest loss: 0.044584\tAccuracy: 98.48%\n",
      "9\tValidation loss: 0.053621\tBest loss: 0.044584\tAccuracy: 98.67%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75, total=  18.1s\n",
      "[CV] learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75 \n",
      "0\tValidation loss: 0.202799\tBest loss: 0.202799\tAccuracy: 95.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tValidation loss: 0.055996\tBest loss: 0.055996\tAccuracy: 98.05%\n",
      "2\tValidation loss: 0.066087\tBest loss: 0.055996\tAccuracy: 98.08%\n",
      "3\tValidation loss: 0.043304\tBest loss: 0.043304\tAccuracy: 98.75%\n",
      "4\tValidation loss: 0.079713\tBest loss: 0.043304\tAccuracy: 98.05%\n",
      "5\tValidation loss: 0.040813\tBest loss: 0.040813\tAccuracy: 98.79%\n",
      "6\tValidation loss: 0.042691\tBest loss: 0.040813\tAccuracy: 98.94%\n",
      "7\tValidation loss: 0.048238\tBest loss: 0.040813\tAccuracy: 98.79%\n",
      "8\tValidation loss: 0.057427\tBest loss: 0.040813\tAccuracy: 98.55%\n",
      "9\tValidation loss: 0.061739\tBest loss: 0.040813\tAccuracy: 98.55%\n",
      "10\tValidation loss: 0.058114\tBest loss: 0.040813\tAccuracy: 98.67%\n",
      "11\tValidation loss: 0.034158\tBest loss: 0.034158\tAccuracy: 98.91%\n",
      "12\tValidation loss: 0.034655\tBest loss: 0.034158\tAccuracy: 99.06%\n",
      "13\tValidation loss: 0.028408\tBest loss: 0.028408\tAccuracy: 99.06%\n",
      "14\tValidation loss: 0.044818\tBest loss: 0.028408\tAccuracy: 98.75%\n",
      "15\tValidation loss: 0.050839\tBest loss: 0.028408\tAccuracy: 98.75%\n",
      "16\tValidation loss: 0.041998\tBest loss: 0.028408\tAccuracy: 98.87%\n",
      "17\tValidation loss: 0.036959\tBest loss: 0.028408\tAccuracy: 98.98%\n",
      "18\tValidation loss: 0.051677\tBest loss: 0.028408\tAccuracy: 98.83%\n",
      "19\tValidation loss: 0.030934\tBest loss: 0.028408\tAccuracy: 99.22%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=45, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75, total=  33.1s\n",
      "[CV] learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65 \n",
      "0\tValidation loss: 0.082010\tBest loss: 0.082010\tAccuracy: 97.81%\n",
      "1\tValidation loss: 0.059277\tBest loss: 0.059277\tAccuracy: 98.16%\n",
      "2\tValidation loss: 0.090473\tBest loss: 0.059277\tAccuracy: 97.22%\n",
      "3\tValidation loss: 0.054429\tBest loss: 0.054429\tAccuracy: 98.36%\n",
      "4\tValidation loss: 0.051778\tBest loss: 0.051778\tAccuracy: 98.48%\n",
      "5\tValidation loss: 0.055140\tBest loss: 0.051778\tAccuracy: 98.59%\n",
      "6\tValidation loss: 0.043865\tBest loss: 0.043865\tAccuracy: 98.55%\n",
      "7\tValidation loss: 0.038755\tBest loss: 0.038755\tAccuracy: 98.79%\n",
      "8\tValidation loss: 0.031635\tBest loss: 0.031635\tAccuracy: 99.02%\n",
      "9\tValidation loss: 0.054705\tBest loss: 0.031635\tAccuracy: 98.59%\n",
      "10\tValidation loss: 0.049084\tBest loss: 0.031635\tAccuracy: 98.87%\n",
      "11\tValidation loss: 0.043372\tBest loss: 0.031635\tAccuracy: 98.67%\n",
      "12\tValidation loss: 0.052234\tBest loss: 0.031635\tAccuracy: 98.59%\n",
      "13\tValidation loss: 0.064718\tBest loss: 0.031635\tAccuracy: 98.67%\n",
      "14\tValidation loss: 0.048634\tBest loss: 0.031635\tAccuracy: 98.79%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65, total=  28.9s\n",
      "[CV] learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65 \n",
      "0\tValidation loss: 0.121379\tBest loss: 0.121379\tAccuracy: 96.91%\n",
      "1\tValidation loss: 0.057278\tBest loss: 0.057278\tAccuracy: 98.24%\n",
      "2\tValidation loss: 0.108766\tBest loss: 0.057278\tAccuracy: 96.83%\n",
      "3\tValidation loss: 0.062071\tBest loss: 0.057278\tAccuracy: 98.28%\n",
      "4\tValidation loss: 0.090683\tBest loss: 0.057278\tAccuracy: 97.69%\n",
      "5\tValidation loss: 0.061516\tBest loss: 0.057278\tAccuracy: 98.36%\n",
      "6\tValidation loss: 0.070933\tBest loss: 0.057278\tAccuracy: 98.36%\n",
      "7\tValidation loss: 0.053015\tBest loss: 0.053015\tAccuracy: 98.59%\n",
      "8\tValidation loss: 0.050122\tBest loss: 0.050122\tAccuracy: 98.59%\n",
      "9\tValidation loss: 0.072918\tBest loss: 0.050122\tAccuracy: 98.32%\n",
      "10\tValidation loss: 0.065827\tBest loss: 0.050122\tAccuracy: 98.24%\n",
      "11\tValidation loss: 0.047020\tBest loss: 0.047020\tAccuracy: 98.79%\n",
      "12\tValidation loss: 0.057059\tBest loss: 0.047020\tAccuracy: 98.63%\n",
      "13\tValidation loss: 0.044975\tBest loss: 0.044975\tAccuracy: 98.71%\n",
      "14\tValidation loss: 0.050713\tBest loss: 0.044975\tAccuracy: 98.83%\n",
      "15\tValidation loss: 0.058813\tBest loss: 0.044975\tAccuracy: 98.75%\n",
      "16\tValidation loss: 0.048785\tBest loss: 0.044975\tAccuracy: 98.83%\n",
      "17\tValidation loss: 0.052677\tBest loss: 0.044975\tAccuracy: 98.48%\n",
      "18\tValidation loss: 0.056594\tBest loss: 0.044975\tAccuracy: 98.87%\n",
      "19\tValidation loss: 0.049559\tBest loss: 0.044975\tAccuracy: 98.91%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65, total=  38.3s\n",
      "[CV] learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65 \n",
      "0\tValidation loss: 0.102700\tBest loss: 0.102700\tAccuracy: 97.65%\n",
      "1\tValidation loss: 0.060191\tBest loss: 0.060191\tAccuracy: 98.75%\n",
      "2\tValidation loss: 0.061862\tBest loss: 0.060191\tAccuracy: 98.12%\n",
      "3\tValidation loss: 0.060400\tBest loss: 0.060191\tAccuracy: 98.08%\n",
      "4\tValidation loss: 0.043794\tBest loss: 0.043794\tAccuracy: 98.83%\n",
      "5\tValidation loss: 0.036683\tBest loss: 0.036683\tAccuracy: 98.75%\n",
      "6\tValidation loss: 0.058155\tBest loss: 0.036683\tAccuracy: 98.20%\n",
      "7\tValidation loss: 0.057643\tBest loss: 0.036683\tAccuracy: 98.71%\n",
      "8\tValidation loss: 0.057101\tBest loss: 0.036683\tAccuracy: 98.51%\n",
      "9\tValidation loss: 0.052438\tBest loss: 0.036683\tAccuracy: 98.51%\n",
      "10\tValidation loss: 0.038128\tBest loss: 0.036683\tAccuracy: 99.26%\n",
      "11\tValidation loss: 0.056356\tBest loss: 0.036683\tAccuracy: 98.63%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65, total=  18.3s\n",
      "[CV] learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70 \n",
      "0\tValidation loss: 0.098522\tBest loss: 0.098522\tAccuracy: 97.81%\n",
      "1\tValidation loss: 0.080233\tBest loss: 0.080233\tAccuracy: 98.08%\n",
      "2\tValidation loss: 0.068767\tBest loss: 0.068767\tAccuracy: 98.01%\n",
      "3\tValidation loss: 0.057095\tBest loss: 0.057095\tAccuracy: 98.28%\n",
      "4\tValidation loss: 0.067008\tBest loss: 0.057095\tAccuracy: 98.12%\n",
      "5\tValidation loss: 0.058910\tBest loss: 0.057095\tAccuracy: 98.55%\n",
      "6\tValidation loss: 0.038421\tBest loss: 0.038421\tAccuracy: 98.91%\n",
      "7\tValidation loss: 0.071075\tBest loss: 0.038421\tAccuracy: 98.36%\n",
      "8\tValidation loss: 0.063073\tBest loss: 0.038421\tAccuracy: 98.28%\n",
      "9\tValidation loss: 0.057488\tBest loss: 0.038421\tAccuracy: 98.75%\n",
      "10\tValidation loss: 0.049557\tBest loss: 0.038421\tAccuracy: 98.75%\n",
      "11\tValidation loss: 0.039810\tBest loss: 0.038421\tAccuracy: 99.06%\n",
      "12\tValidation loss: 0.061837\tBest loss: 0.038421\tAccuracy: 98.55%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70, total=  18.7s\n",
      "[CV] learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70 \n",
      "0\tValidation loss: 0.123638\tBest loss: 0.123638\tAccuracy: 96.68%\n",
      "1\tValidation loss: 0.048079\tBest loss: 0.048079\tAccuracy: 98.55%\n",
      "2\tValidation loss: 0.082311\tBest loss: 0.048079\tAccuracy: 97.58%\n",
      "3\tValidation loss: 0.059053\tBest loss: 0.048079\tAccuracy: 98.28%\n",
      "4\tValidation loss: 0.056156\tBest loss: 0.048079\tAccuracy: 98.59%\n",
      "5\tValidation loss: 0.071631\tBest loss: 0.048079\tAccuracy: 98.36%\n",
      "6\tValidation loss: 0.044482\tBest loss: 0.044482\tAccuracy: 98.79%\n",
      "7\tValidation loss: 0.049969\tBest loss: 0.044482\tAccuracy: 98.67%\n",
      "8\tValidation loss: 0.053734\tBest loss: 0.044482\tAccuracy: 98.87%\n",
      "9\tValidation loss: 0.057046\tBest loss: 0.044482\tAccuracy: 98.40%\n",
      "10\tValidation loss: 0.059210\tBest loss: 0.044482\tAccuracy: 98.44%\n",
      "11\tValidation loss: 0.044404\tBest loss: 0.044404\tAccuracy: 98.83%\n",
      "12\tValidation loss: 0.048075\tBest loss: 0.044404\tAccuracy: 98.83%\n",
      "13\tValidation loss: 0.041242\tBest loss: 0.041242\tAccuracy: 98.87%\n",
      "14\tValidation loss: 0.037449\tBest loss: 0.037449\tAccuracy: 98.71%\n",
      "15\tValidation loss: 0.059479\tBest loss: 0.037449\tAccuracy: 98.71%\n",
      "16\tValidation loss: 0.054563\tBest loss: 0.037449\tAccuracy: 98.87%\n",
      "17\tValidation loss: 0.040756\tBest loss: 0.037449\tAccuracy: 98.91%\n",
      "18\tValidation loss: 0.055704\tBest loss: 0.037449\tAccuracy: 98.59%\n",
      "19\tValidation loss: 0.057695\tBest loss: 0.037449\tAccuracy: 98.71%\n",
      "20\tValidation loss: 0.039648\tBest loss: 0.037449\tAccuracy: 98.98%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70, total=  28.9s\n",
      "[CV] learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.069197\tBest loss: 0.069197\tAccuracy: 98.44%\n",
      "1\tValidation loss: 0.058152\tBest loss: 0.058152\tAccuracy: 98.48%\n",
      "2\tValidation loss: 0.061270\tBest loss: 0.058152\tAccuracy: 98.28%\n",
      "3\tValidation loss: 0.036191\tBest loss: 0.036191\tAccuracy: 98.71%\n",
      "4\tValidation loss: 0.031603\tBest loss: 0.031603\tAccuracy: 98.98%\n",
      "5\tValidation loss: 0.077961\tBest loss: 0.031603\tAccuracy: 97.77%\n",
      "6\tValidation loss: 0.052401\tBest loss: 0.031603\tAccuracy: 98.44%\n",
      "7\tValidation loss: 0.058968\tBest loss: 0.031603\tAccuracy: 98.55%\n",
      "8\tValidation loss: 0.043009\tBest loss: 0.031603\tAccuracy: 98.79%\n",
      "9\tValidation loss: 0.039525\tBest loss: 0.031603\tAccuracy: 98.98%\n",
      "10\tValidation loss: 0.044521\tBest loss: 0.031603\tAccuracy: 98.79%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70, total=  16.0s\n",
      "[CV] learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75 \n",
      "0\tValidation loss: 0.079772\tBest loss: 0.079772\tAccuracy: 97.89%\n",
      "1\tValidation loss: 0.076900\tBest loss: 0.076900\tAccuracy: 98.16%\n",
      "2\tValidation loss: 0.069469\tBest loss: 0.069469\tAccuracy: 97.85%\n",
      "3\tValidation loss: 0.045367\tBest loss: 0.045367\tAccuracy: 98.59%\n",
      "4\tValidation loss: 0.039447\tBest loss: 0.039447\tAccuracy: 98.91%\n",
      "5\tValidation loss: 0.035049\tBest loss: 0.035049\tAccuracy: 98.98%\n",
      "6\tValidation loss: 0.033816\tBest loss: 0.033816\tAccuracy: 99.02%\n",
      "7\tValidation loss: 0.039454\tBest loss: 0.033816\tAccuracy: 98.87%\n",
      "8\tValidation loss: 0.040887\tBest loss: 0.033816\tAccuracy: 99.02%\n",
      "9\tValidation loss: 0.058487\tBest loss: 0.033816\tAccuracy: 98.63%\n",
      "10\tValidation loss: 0.058891\tBest loss: 0.033816\tAccuracy: 98.63%\n",
      "11\tValidation loss: 0.047463\tBest loss: 0.033816\tAccuracy: 98.91%\n",
      "12\tValidation loss: 0.051924\tBest loss: 0.033816\tAccuracy: 98.79%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75, total=  18.9s\n",
      "[CV] learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75 \n",
      "0\tValidation loss: 0.127779\tBest loss: 0.127779\tAccuracy: 96.79%\n",
      "1\tValidation loss: 0.065644\tBest loss: 0.065644\tAccuracy: 98.44%\n",
      "2\tValidation loss: 0.072358\tBest loss: 0.065644\tAccuracy: 98.36%\n",
      "3\tValidation loss: 0.048277\tBest loss: 0.048277\tAccuracy: 98.75%\n",
      "4\tValidation loss: 0.056642\tBest loss: 0.048277\tAccuracy: 98.51%\n",
      "5\tValidation loss: 0.057839\tBest loss: 0.048277\tAccuracy: 98.36%\n",
      "6\tValidation loss: 0.047054\tBest loss: 0.047054\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.048230\tBest loss: 0.047054\tAccuracy: 98.63%\n",
      "8\tValidation loss: 0.059721\tBest loss: 0.047054\tAccuracy: 98.79%\n",
      "9\tValidation loss: 0.074006\tBest loss: 0.047054\tAccuracy: 98.48%\n",
      "10\tValidation loss: 0.047472\tBest loss: 0.047054\tAccuracy: 98.87%\n",
      "11\tValidation loss: 0.049740\tBest loss: 0.047054\tAccuracy: 98.71%\n",
      "12\tValidation loss: 0.050852\tBest loss: 0.047054\tAccuracy: 98.48%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75, total=  19.0s\n",
      "[CV] learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75 \n",
      "0\tValidation loss: 0.095069\tBest loss: 0.095069\tAccuracy: 98.16%\n",
      "1\tValidation loss: 0.055467\tBest loss: 0.055467\tAccuracy: 98.16%\n",
      "2\tValidation loss: 0.065559\tBest loss: 0.055467\tAccuracy: 97.97%\n",
      "3\tValidation loss: 0.045553\tBest loss: 0.045553\tAccuracy: 98.40%\n",
      "4\tValidation loss: 0.048982\tBest loss: 0.045553\tAccuracy: 98.75%\n",
      "5\tValidation loss: 0.049750\tBest loss: 0.045553\tAccuracy: 98.59%\n",
      "6\tValidation loss: 0.068788\tBest loss: 0.045553\tAccuracy: 98.01%\n",
      "7\tValidation loss: 0.070899\tBest loss: 0.045553\tAccuracy: 98.16%\n",
      "8\tValidation loss: 0.038678\tBest loss: 0.038678\tAccuracy: 98.94%\n",
      "9\tValidation loss: 0.042780\tBest loss: 0.038678\tAccuracy: 98.98%\n",
      "10\tValidation loss: 0.045874\tBest loss: 0.038678\tAccuracy: 98.94%\n",
      "11\tValidation loss: 0.055021\tBest loss: 0.038678\tAccuracy: 98.51%\n",
      "12\tValidation loss: 0.087112\tBest loss: 0.038678\tAccuracy: 97.73%\n",
      "13\tValidation loss: 0.033763\tBest loss: 0.033763\tAccuracy: 99.22%\n",
      "14\tValidation loss: 0.032062\tBest loss: 0.032062\tAccuracy: 99.10%\n",
      "15\tValidation loss: 0.046440\tBest loss: 0.032062\tAccuracy: 98.79%\n",
      "16\tValidation loss: 0.041189\tBest loss: 0.032062\tAccuracy: 98.83%\n",
      "17\tValidation loss: 0.038111\tBest loss: 0.032062\tAccuracy: 99.10%\n",
      "18\tValidation loss: 0.038652\tBest loss: 0.032062\tAccuracy: 98.79%\n",
      "19\tValidation loss: 0.044199\tBest loss: 0.032062\tAccuracy: 99.18%\n",
      "20\tValidation loss: 0.058094\tBest loss: 0.032062\tAccuracy: 98.20%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=50, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75, total=  30.4s\n",
      "[CV] learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65 \n",
      "0\tValidation loss: 0.147401\tBest loss: 0.147401\tAccuracy: 97.34%\n",
      "1\tValidation loss: 0.073894\tBest loss: 0.073894\tAccuracy: 98.12%\n",
      "2\tValidation loss: 0.051774\tBest loss: 0.051774\tAccuracy: 98.55%\n",
      "3\tValidation loss: 0.042963\tBest loss: 0.042963\tAccuracy: 98.63%\n",
      "4\tValidation loss: 0.037205\tBest loss: 0.037205\tAccuracy: 98.98%\n",
      "5\tValidation loss: 0.047195\tBest loss: 0.037205\tAccuracy: 98.63%\n",
      "6\tValidation loss: 0.050592\tBest loss: 0.037205\tAccuracy: 98.67%\n",
      "7\tValidation loss: 0.054536\tBest loss: 0.037205\tAccuracy: 98.75%\n",
      "8\tValidation loss: 0.029482\tBest loss: 0.029482\tAccuracy: 99.14%\n",
      "9\tValidation loss: 0.048329\tBest loss: 0.029482\tAccuracy: 98.87%\n",
      "10\tValidation loss: 0.065939\tBest loss: 0.029482\tAccuracy: 98.40%\n",
      "11\tValidation loss: 0.035704\tBest loss: 0.029482\tAccuracy: 98.94%\n",
      "12\tValidation loss: 0.043254\tBest loss: 0.029482\tAccuracy: 98.67%\n",
      "13\tValidation loss: 0.067296\tBest loss: 0.029482\tAccuracy: 98.44%\n",
      "14\tValidation loss: 0.051695\tBest loss: 0.029482\tAccuracy: 98.48%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65, total=  25.6s\n",
      "[CV] learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65 \n",
      "0\tValidation loss: 0.106100\tBest loss: 0.106100\tAccuracy: 97.34%\n",
      "1\tValidation loss: 0.088435\tBest loss: 0.088435\tAccuracy: 97.62%\n",
      "2\tValidation loss: 0.059219\tBest loss: 0.059219\tAccuracy: 98.44%\n",
      "3\tValidation loss: 0.051275\tBest loss: 0.051275\tAccuracy: 98.44%\n",
      "4\tValidation loss: 0.043628\tBest loss: 0.043628\tAccuracy: 98.87%\n",
      "5\tValidation loss: 0.059708\tBest loss: 0.043628\tAccuracy: 98.40%\n",
      "6\tValidation loss: 0.074376\tBest loss: 0.043628\tAccuracy: 97.62%\n",
      "7\tValidation loss: 0.078393\tBest loss: 0.043628\tAccuracy: 98.20%\n",
      "8\tValidation loss: 0.045248\tBest loss: 0.043628\tAccuracy: 98.75%\n",
      "9\tValidation loss: 0.069191\tBest loss: 0.043628\tAccuracy: 98.83%\n",
      "10\tValidation loss: 0.055845\tBest loss: 0.043628\tAccuracy: 98.79%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65, total=  21.1s\n",
      "[CV] learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65 \n",
      "0\tValidation loss: 0.168935\tBest loss: 0.168935\tAccuracy: 95.93%\n",
      "1\tValidation loss: 0.055758\tBest loss: 0.055758\tAccuracy: 98.16%\n",
      "2\tValidation loss: 0.062738\tBest loss: 0.055758\tAccuracy: 97.81%\n",
      "3\tValidation loss: 0.052525\tBest loss: 0.052525\tAccuracy: 98.12%\n",
      "4\tValidation loss: 0.052775\tBest loss: 0.052525\tAccuracy: 98.71%\n",
      "5\tValidation loss: 0.037857\tBest loss: 0.037857\tAccuracy: 98.98%\n",
      "6\tValidation loss: 0.037070\tBest loss: 0.037070\tAccuracy: 98.94%\n",
      "7\tValidation loss: 0.051910\tBest loss: 0.037070\tAccuracy: 98.63%\n",
      "8\tValidation loss: 0.037088\tBest loss: 0.037070\tAccuracy: 98.91%\n",
      "9\tValidation loss: 0.042330\tBest loss: 0.037070\tAccuracy: 99.02%\n",
      "10\tValidation loss: 0.041710\tBest loss: 0.037070\tAccuracy: 98.98%\n",
      "11\tValidation loss: 0.052103\tBest loss: 0.037070\tAccuracy: 98.63%\n",
      "12\tValidation loss: 0.034386\tBest loss: 0.034386\tAccuracy: 99.02%\n",
      "13\tValidation loss: 0.035514\tBest loss: 0.034386\tAccuracy: 99.06%\n",
      "14\tValidation loss: 0.040916\tBest loss: 0.034386\tAccuracy: 99.06%\n",
      "15\tValidation loss: 0.038016\tBest loss: 0.034386\tAccuracy: 99.02%\n",
      "16\tValidation loss: 0.046926\tBest loss: 0.034386\tAccuracy: 98.83%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\tValidation loss: 0.044766\tBest loss: 0.034386\tAccuracy: 99.06%\n",
      "18\tValidation loss: 0.051972\tBest loss: 0.034386\tAccuracy: 98.98%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=65, total=  29.7s\n",
      "[CV] learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70 \n",
      "0\tValidation loss: 0.075533\tBest loss: 0.075533\tAccuracy: 98.01%\n",
      "1\tValidation loss: 0.094598\tBest loss: 0.075533\tAccuracy: 97.69%\n",
      "2\tValidation loss: 0.058285\tBest loss: 0.058285\tAccuracy: 98.36%\n",
      "3\tValidation loss: 0.056714\tBest loss: 0.056714\tAccuracy: 98.32%\n",
      "4\tValidation loss: 0.059758\tBest loss: 0.056714\tAccuracy: 98.24%\n",
      "5\tValidation loss: 0.041241\tBest loss: 0.041241\tAccuracy: 98.87%\n",
      "6\tValidation loss: 0.041631\tBest loss: 0.041241\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.057423\tBest loss: 0.041241\tAccuracy: 98.71%\n",
      "8\tValidation loss: 0.037379\tBest loss: 0.037379\tAccuracy: 99.10%\n",
      "9\tValidation loss: 0.042850\tBest loss: 0.037379\tAccuracy: 98.91%\n",
      "10\tValidation loss: 0.047923\tBest loss: 0.037379\tAccuracy: 98.87%\n",
      "11\tValidation loss: 0.040792\tBest loss: 0.037379\tAccuracy: 98.79%\n",
      "12\tValidation loss: 0.043781\tBest loss: 0.037379\tAccuracy: 99.02%\n",
      "13\tValidation loss: 0.071024\tBest loss: 0.037379\tAccuracy: 98.36%\n",
      "14\tValidation loss: 0.054702\tBest loss: 0.037379\tAccuracy: 98.71%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70, total=  25.3s\n",
      "[CV] learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70 \n",
      "0\tValidation loss: 0.095019\tBest loss: 0.095019\tAccuracy: 97.38%\n",
      "1\tValidation loss: 0.058023\tBest loss: 0.058023\tAccuracy: 98.28%\n",
      "2\tValidation loss: 0.054186\tBest loss: 0.054186\tAccuracy: 98.36%\n",
      "3\tValidation loss: 0.051006\tBest loss: 0.051006\tAccuracy: 98.71%\n",
      "4\tValidation loss: 0.042633\tBest loss: 0.042633\tAccuracy: 98.87%\n",
      "5\tValidation loss: 0.058649\tBest loss: 0.042633\tAccuracy: 98.44%\n",
      "6\tValidation loss: 0.052767\tBest loss: 0.042633\tAccuracy: 98.51%\n",
      "7\tValidation loss: 0.043747\tBest loss: 0.042633\tAccuracy: 98.59%\n",
      "8\tValidation loss: 0.042749\tBest loss: 0.042633\tAccuracy: 98.91%\n",
      "9\tValidation loss: 0.051663\tBest loss: 0.042633\tAccuracy: 98.63%\n",
      "10\tValidation loss: 0.055993\tBest loss: 0.042633\tAccuracy: 98.59%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70, total=  17.6s\n",
      "[CV] learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70 \n",
      "0\tValidation loss: 0.217032\tBest loss: 0.217032\tAccuracy: 95.15%\n",
      "1\tValidation loss: 0.092192\tBest loss: 0.092192\tAccuracy: 97.69%\n",
      "2\tValidation loss: 0.053465\tBest loss: 0.053465\tAccuracy: 98.28%\n",
      "3\tValidation loss: 0.051709\tBest loss: 0.051709\tAccuracy: 98.20%\n",
      "4\tValidation loss: 0.070249\tBest loss: 0.051709\tAccuracy: 98.12%\n",
      "5\tValidation loss: 0.055681\tBest loss: 0.051709\tAccuracy: 98.32%\n",
      "6\tValidation loss: 0.042354\tBest loss: 0.042354\tAccuracy: 98.44%\n",
      "7\tValidation loss: 0.063482\tBest loss: 0.042354\tAccuracy: 98.51%\n",
      "8\tValidation loss: 0.039489\tBest loss: 0.039489\tAccuracy: 98.87%\n",
      "9\tValidation loss: 0.041739\tBest loss: 0.039489\tAccuracy: 98.79%\n",
      "10\tValidation loss: 0.057362\tBest loss: 0.039489\tAccuracy: 98.67%\n",
      "11\tValidation loss: 0.037560\tBest loss: 0.037560\tAccuracy: 99.06%\n",
      "12\tValidation loss: 0.049831\tBest loss: 0.037560\tAccuracy: 98.67%\n",
      "13\tValidation loss: 0.035679\tBest loss: 0.035679\tAccuracy: 98.98%\n",
      "14\tValidation loss: 0.045806\tBest loss: 0.035679\tAccuracy: 98.87%\n",
      "15\tValidation loss: 0.055598\tBest loss: 0.035679\tAccuracy: 98.83%\n",
      "16\tValidation loss: 0.036795\tBest loss: 0.035679\tAccuracy: 98.94%\n",
      "17\tValidation loss: 0.063719\tBest loss: 0.035679\tAccuracy: 98.79%\n",
      "18\tValidation loss: 0.041253\tBest loss: 0.035679\tAccuracy: 98.91%\n",
      "19\tValidation loss: 0.047561\tBest loss: 0.035679\tAccuracy: 99.02%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=70, total=  32.3s\n",
      "[CV] learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75 \n",
      "0\tValidation loss: 0.090116\tBest loss: 0.090116\tAccuracy: 97.69%\n",
      "1\tValidation loss: 0.092612\tBest loss: 0.090116\tAccuracy: 97.97%\n",
      "2\tValidation loss: 0.053998\tBest loss: 0.053998\tAccuracy: 98.55%\n",
      "3\tValidation loss: 0.065358\tBest loss: 0.053998\tAccuracy: 98.36%\n",
      "4\tValidation loss: 0.043609\tBest loss: 0.043609\tAccuracy: 98.59%\n",
      "5\tValidation loss: 0.040776\tBest loss: 0.040776\tAccuracy: 99.10%\n",
      "6\tValidation loss: 0.048691\tBest loss: 0.040776\tAccuracy: 98.51%\n",
      "7\tValidation loss: 0.054020\tBest loss: 0.040776\tAccuracy: 98.55%\n",
      "8\tValidation loss: 0.041885\tBest loss: 0.040776\tAccuracy: 98.83%\n",
      "9\tValidation loss: 0.040117\tBest loss: 0.040117\tAccuracy: 99.14%\n",
      "10\tValidation loss: 0.056928\tBest loss: 0.040117\tAccuracy: 98.51%\n",
      "11\tValidation loss: 0.043963\tBest loss: 0.040117\tAccuracy: 99.10%\n",
      "12\tValidation loss: 0.062903\tBest loss: 0.040117\tAccuracy: 98.24%\n",
      "13\tValidation loss: 0.052418\tBest loss: 0.040117\tAccuracy: 98.83%\n",
      "14\tValidation loss: 0.039551\tBest loss: 0.039551\tAccuracy: 98.71%\n",
      "15\tValidation loss: 0.050775\tBest loss: 0.039551\tAccuracy: 98.67%\n",
      "16\tValidation loss: 0.052559\tBest loss: 0.039551\tAccuracy: 98.83%\n",
      "17\tValidation loss: 0.028913\tBest loss: 0.028913\tAccuracy: 99.34%\n",
      "18\tValidation loss: 0.040689\tBest loss: 0.028913\tAccuracy: 99.14%\n",
      "19\tValidation loss: 0.049512\tBest loss: 0.028913\tAccuracy: 99.02%\n",
      "20\tValidation loss: 0.034303\tBest loss: 0.028913\tAccuracy: 99.18%\n",
      "21\tValidation loss: 0.036732\tBest loss: 0.028913\tAccuracy: 99.02%\n",
      "22\tValidation loss: 0.042875\tBest loss: 0.028913\tAccuracy: 99.02%\n",
      "23\tValidation loss: 0.040521\tBest loss: 0.028913\tAccuracy: 99.02%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75, total=  33.6s\n",
      "[CV] learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75 \n",
      "0\tValidation loss: 0.145328\tBest loss: 0.145328\tAccuracy: 96.52%\n",
      "1\tValidation loss: 0.070036\tBest loss: 0.070036\tAccuracy: 97.97%\n",
      "2\tValidation loss: 0.054747\tBest loss: 0.054747\tAccuracy: 98.20%\n",
      "3\tValidation loss: 0.061742\tBest loss: 0.054747\tAccuracy: 98.36%\n",
      "4\tValidation loss: 0.050182\tBest loss: 0.050182\tAccuracy: 98.59%\n",
      "5\tValidation loss: 0.051231\tBest loss: 0.050182\tAccuracy: 98.55%\n",
      "6\tValidation loss: 0.061681\tBest loss: 0.050182\tAccuracy: 98.40%\n",
      "7\tValidation loss: 0.061042\tBest loss: 0.050182\tAccuracy: 98.36%\n",
      "8\tValidation loss: 0.049327\tBest loss: 0.049327\tAccuracy: 98.87%\n",
      "9\tValidation loss: 0.045550\tBest loss: 0.045550\tAccuracy: 98.83%\n",
      "10\tValidation loss: 0.061631\tBest loss: 0.045550\tAccuracy: 98.44%\n",
      "11\tValidation loss: 0.053634\tBest loss: 0.045550\tAccuracy: 98.83%\n",
      "12\tValidation loss: 0.039377\tBest loss: 0.039377\tAccuracy: 98.91%\n",
      "13\tValidation loss: 0.041891\tBest loss: 0.039377\tAccuracy: 98.91%\n",
      "14\tValidation loss: 0.061524\tBest loss: 0.039377\tAccuracy: 98.51%\n",
      "15\tValidation loss: 0.051286\tBest loss: 0.039377\tAccuracy: 98.63%\n",
      "16\tValidation loss: 0.059849\tBest loss: 0.039377\tAccuracy: 98.55%\n",
      "17\tValidation loss: 0.056886\tBest loss: 0.039377\tAccuracy: 98.40%\n",
      "18\tValidation loss: 0.049980\tBest loss: 0.039377\tAccuracy: 98.67%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75, total=  26.2s\n",
      "[CV] learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75 \n",
      "0\tValidation loss: 0.081440\tBest loss: 0.081440\tAccuracy: 97.69%\n",
      "1\tValidation loss: 0.056835\tBest loss: 0.056835\tAccuracy: 98.51%\n",
      "2\tValidation loss: 0.059616\tBest loss: 0.056835\tAccuracy: 97.97%\n",
      "3\tValidation loss: 0.045980\tBest loss: 0.045980\tAccuracy: 98.59%\n",
      "4\tValidation loss: 0.043328\tBest loss: 0.043328\tAccuracy: 98.83%\n",
      "5\tValidation loss: 0.048649\tBest loss: 0.043328\tAccuracy: 98.67%\n",
      "6\tValidation loss: 0.053853\tBest loss: 0.043328\tAccuracy: 98.28%\n",
      "7\tValidation loss: 0.070838\tBest loss: 0.043328\tAccuracy: 98.24%\n",
      "8\tValidation loss: 0.036685\tBest loss: 0.036685\tAccuracy: 98.87%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\tValidation loss: 0.049015\tBest loss: 0.036685\tAccuracy: 99.02%\n",
      "10\tValidation loss: 0.046841\tBest loss: 0.036685\tAccuracy: 98.79%\n",
      "11\tValidation loss: 0.060210\tBest loss: 0.036685\tAccuracy: 98.51%\n",
      "12\tValidation loss: 0.043711\tBest loss: 0.036685\tAccuracy: 98.94%\n",
      "13\tValidation loss: 0.080342\tBest loss: 0.036685\tAccuracy: 98.16%\n",
      "14\tValidation loss: 0.055947\tBest loss: 0.036685\tAccuracy: 98.71%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=55, activation=<function relu at 0x11d863a60>, batch_norm_momentum=0.99, n_neurons=75, total=  22.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 11.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.164266\tBest loss: 0.164266\tAccuracy: 96.13%\n",
      "1\tValidation loss: 0.042195\tBest loss: 0.042195\tAccuracy: 98.40%\n",
      "2\tValidation loss: 0.040929\tBest loss: 0.040929\tAccuracy: 98.83%\n",
      "3\tValidation loss: 0.064607\tBest loss: 0.040929\tAccuracy: 98.20%\n",
      "4\tValidation loss: 0.032527\tBest loss: 0.032527\tAccuracy: 98.94%\n",
      "5\tValidation loss: 0.036257\tBest loss: 0.032527\tAccuracy: 98.91%\n",
      "6\tValidation loss: 0.036971\tBest loss: 0.032527\tAccuracy: 99.06%\n",
      "7\tValidation loss: 0.028221\tBest loss: 0.028221\tAccuracy: 99.18%\n",
      "8\tValidation loss: 0.037031\tBest loss: 0.028221\tAccuracy: 98.91%\n",
      "9\tValidation loss: 0.031844\tBest loss: 0.028221\tAccuracy: 99.14%\n",
      "10\tValidation loss: 0.051240\tBest loss: 0.028221\tAccuracy: 98.79%\n",
      "11\tValidation loss: 0.030088\tBest loss: 0.028221\tAccuracy: 99.26%\n",
      "12\tValidation loss: 0.027904\tBest loss: 0.027904\tAccuracy: 99.34%\n",
      "13\tValidation loss: 0.060909\tBest loss: 0.027904\tAccuracy: 98.67%\n",
      "14\tValidation loss: 0.031512\tBest loss: 0.027904\tAccuracy: 99.14%\n",
      "15\tValidation loss: 0.043620\tBest loss: 0.027904\tAccuracy: 99.14%\n",
      "16\tValidation loss: 0.050287\tBest loss: 0.027904\tAccuracy: 99.02%\n",
      "17\tValidation loss: 0.040426\tBest loss: 0.027904\tAccuracy: 98.94%\n",
      "18\tValidation loss: 0.037877\tBest loss: 0.027904\tAccuracy: 99.34%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=DNNClassifier(activation=<function elu at 0x11d853730>,\n",
       "       batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
       "       initializer=<tensorflow.python.ops.init_ops.VarianceScaling object at 0x112ea8fd0>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=100,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42),\n",
       "          fit_params={'y_valid': array([0, 4, ..., 1, 2], dtype=int32), 'n_epochs': 1000, 'X_valid': array([[0., 0., ..., 0., 0.],\n",
       "       [0., 0., ..., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., ..., 0., 0.],\n",
       "       [0., 0., ..., 0., 0.]], dtype=float32)},\n",
       "          iid=True, n_iter=9, n_jobs=1,\n",
       "          param_distributions={'learning_rate': [0.01], 'batch_size': [45, 50, 55], 'activation': [<function relu at 0x11d863a60>], 'batch_norm_momentum': [0.99], 'n_neurons': [65, 70, 75]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": [65, 70, 75],\n",
    "    \"batch_size\": [45, 50, 55],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"activation\": [tf.nn.relu],\n",
    "    # you could also try exploring different numbers of hidden layers, different optimizers, etc.\n",
    "    #\"n_hidden_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    #\"optimizer_class\": [tf.train.AdamOptimizer, partial(tf.train.MomentumOptimizer, momentum=0.95)],\n",
    "    \"batch_norm_momentum\": [0.99],\n",
    "}\n",
    "\n",
    "rnd_search_bn = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=9,\n",
    "                                   fit_params={\"X_valid\": X_valid1, \"y_valid\": y_valid1, \"n_epochs\": 1000},\n",
    "                                   random_state=42, verbose=2)\n",
    "rnd_search_bn.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': <function tensorflow.python.ops.gen_nn_ops.relu>,\n",
       " 'batch_norm_momentum': 0.99,\n",
       " 'batch_size': 50,\n",
       " 'learning_rate': 0.01,\n",
       " 'n_neurons': 70}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_bn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9959136018680678"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search_bn.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9975390541408089"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf.predict(X_train1)\n",
    "accuracy_score(y_train1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.113220\tBest loss: 0.113220\tAccuracy: 97.15%\n",
      "1\tValidation loss: 0.094061\tBest loss: 0.094061\tAccuracy: 97.54%\n",
      "2\tValidation loss: 0.085397\tBest loss: 0.085397\tAccuracy: 97.69%\n",
      "3\tValidation loss: 0.089503\tBest loss: 0.085397\tAccuracy: 97.97%\n",
      "4\tValidation loss: 0.079616\tBest loss: 0.079616\tAccuracy: 97.81%\n",
      "5\tValidation loss: 0.078729\tBest loss: 0.078729\tAccuracy: 97.97%\n",
      "6\tValidation loss: 0.078287\tBest loss: 0.078287\tAccuracy: 98.16%\n",
      "7\tValidation loss: 0.087333\tBest loss: 0.078287\tAccuracy: 97.93%\n",
      "8\tValidation loss: 0.096147\tBest loss: 0.078287\tAccuracy: 97.89%\n",
      "9\tValidation loss: 0.100612\tBest loss: 0.078287\tAccuracy: 97.30%\n",
      "10\tValidation loss: 0.204575\tBest loss: 0.078287\tAccuracy: 93.75%\n",
      "11\tValidation loss: 0.229475\tBest loss: 0.078287\tAccuracy: 92.06%\n",
      "12\tValidation loss: 0.201846\tBest loss: 0.078287\tAccuracy: 94.41%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x183457a2f0>,\n",
       "       batch_norm_momentum=None, batch_size=400, dropout_rate=0.5,\n",
       "       initializer=<tensorflow.python.ops.init_ops.VarianceScaling object at 0x112ea8fd0>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=140,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf_dropout = DNNClassifier(activation=leaky_relu(alpha=0.1), batch_size=400, learning_rate=0.01, \n",
    "                                n_neurons=140, random_state=42,\n",
    "                                dropout_rate=0.5)\n",
    "dnn_clf_dropout.fit(X_train1, y_train1, n_epochs=1000, X_valid=X_valid1, y_valid=y_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9836544074722708"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf_dropout.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excersise 9 - transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "restore_saver = tf.train.import_meta_graph(\"./my_best_mnist_model_0_to_4.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "loss = tf.get_default_graph().get_tensor_by_name(\"loss:0\")\n",
    "Y_proba = tf.get_default_graph().get_tensor_by_name(\"Y_proba:0\")\n",
    "logits = Y_proba.op.inputs[0]\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"accuracy:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "five_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2_full = X_train[y_train >= 5]\n",
    "y_train2_full = y_train[y_train >= 5] - 5\n",
    "X_valid2_full = X_valid[y_valid >= 5]\n",
    "y_valid2_full = y_valid[y_valid >= 5] - 5\n",
    "X_test2 = X_test[y_test >= 5]\n",
    "y_test2 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
    "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_best_mnist_model_0_to_4\n",
      "0\tValidation loss: 0.871042\tBest loss: 0.871042\tAccuracy: 69.33%\n",
      "1\tValidation loss: 0.884577\tBest loss: 0.871042\tAccuracy: 74.00%\n",
      "2\tValidation loss: 0.788313\tBest loss: 0.788313\tAccuracy: 74.67%\n",
      "3\tValidation loss: 0.728075\tBest loss: 0.728075\tAccuracy: 78.67%\n",
      "4\tValidation loss: 0.827748\tBest loss: 0.728075\tAccuracy: 76.00%\n",
      "5\tValidation loss: 0.688189\tBest loss: 0.688189\tAccuracy: 80.00%\n",
      "6\tValidation loss: 0.806096\tBest loss: 0.688189\tAccuracy: 76.67%\n",
      "7\tValidation loss: 0.689834\tBest loss: 0.688189\tAccuracy: 81.33%\n",
      "8\tValidation loss: 0.683314\tBest loss: 0.683314\tAccuracy: 79.33%\n",
      "9\tValidation loss: 0.653552\tBest loss: 0.653552\tAccuracy: 80.67%\n",
      "10\tValidation loss: 0.711168\tBest loss: 0.653552\tAccuracy: 79.33%\n",
      "11\tValidation loss: 0.664902\tBest loss: 0.653552\tAccuracy: 79.33%\n",
      "12\tValidation loss: 0.745748\tBest loss: 0.653552\tAccuracy: 75.33%\n",
      "13\tValidation loss: 0.752611\tBest loss: 0.653552\tAccuracy: 78.67%\n",
      "14\tValidation loss: 0.680903\tBest loss: 0.653552\tAccuracy: 77.33%\n",
      "15\tValidation loss: 0.734017\tBest loss: 0.653552\tAccuracy: 80.67%\n",
      "16\tValidation loss: 0.758516\tBest loss: 0.653552\tAccuracy: 77.33%\n",
      "17\tValidation loss: 0.718747\tBest loss: 0.653552\tAccuracy: 78.00%\n",
      "18\tValidation loss: 0.681465\tBest loss: 0.653552\tAccuracy: 80.00%\n",
      "19\tValidation loss: 0.672546\tBest loss: 0.653552\tAccuracy: 80.00%\n",
      "20\tValidation loss: 0.623705\tBest loss: 0.623705\tAccuracy: 82.67%\n",
      "21\tValidation loss: 0.682968\tBest loss: 0.623705\tAccuracy: 80.00%\n",
      "22\tValidation loss: 0.610383\tBest loss: 0.610383\tAccuracy: 81.33%\n",
      "23\tValidation loss: 0.684869\tBest loss: 0.610383\tAccuracy: 78.67%\n",
      "24\tValidation loss: 0.733032\tBest loss: 0.610383\tAccuracy: 79.33%\n",
      "25\tValidation loss: 0.716306\tBest loss: 0.610383\tAccuracy: 80.67%\n",
      "26\tValidation loss: 0.686033\tBest loss: 0.610383\tAccuracy: 79.33%\n",
      "27\tValidation loss: 0.701795\tBest loss: 0.610383\tAccuracy: 80.00%\n",
      "28\tValidation loss: 0.715425\tBest loss: 0.610383\tAccuracy: 80.00%\n",
      "29\tValidation loss: 0.737185\tBest loss: 0.610383\tAccuracy: 79.33%\n",
      "30\tValidation loss: 0.720076\tBest loss: 0.610383\tAccuracy: 78.67%\n",
      "31\tValidation loss: 0.744405\tBest loss: 0.610383\tAccuracy: 77.33%\n",
      "32\tValidation loss: 0.696312\tBest loss: 0.610383\tAccuracy: 80.67%\n",
      "Early stopping!\n",
      "Total training time: 1.2s\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n",
      "Final test accuracy: 76.79%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 10\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_best_mnist_model_0_to_4\")\n",
    "    t0 = time.time()\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden5_out = tf.get_default_graph().get_tensor_by_name(\"hidden5_out:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_best_mnist_model_0_to_4\n",
      "0\tValidation loss: 1.004905\tBest loss: 1.004905\tAccuracy: 64.67%\n",
      "1\tValidation loss: 0.814947\tBest loss: 0.814947\tAccuracy: 70.67%\n",
      "2\tValidation loss: 0.844168\tBest loss: 0.814947\tAccuracy: 70.67%\n",
      "3\tValidation loss: 0.781551\tBest loss: 0.781551\tAccuracy: 80.00%\n",
      "4\tValidation loss: 0.665440\tBest loss: 0.665440\tAccuracy: 78.67%\n",
      "5\tValidation loss: 0.727995\tBest loss: 0.665440\tAccuracy: 77.33%\n",
      "6\tValidation loss: 0.679482\tBest loss: 0.665440\tAccuracy: 78.67%\n",
      "7\tValidation loss: 0.680531\tBest loss: 0.665440\tAccuracy: 79.33%\n",
      "8\tValidation loss: 0.663484\tBest loss: 0.663484\tAccuracy: 78.67%\n",
      "9\tValidation loss: 0.690641\tBest loss: 0.663484\tAccuracy: 77.33%\n",
      "10\tValidation loss: 0.678349\tBest loss: 0.663484\tAccuracy: 78.00%\n",
      "11\tValidation loss: 0.731110\tBest loss: 0.663484\tAccuracy: 78.00%\n",
      "12\tValidation loss: 0.660904\tBest loss: 0.660904\tAccuracy: 79.33%\n",
      "13\tValidation loss: 0.722856\tBest loss: 0.660904\tAccuracy: 78.00%\n",
      "14\tValidation loss: 0.778190\tBest loss: 0.660904\tAccuracy: 78.67%\n",
      "15\tValidation loss: 0.756874\tBest loss: 0.660904\tAccuracy: 76.67%\n",
      "16\tValidation loss: 0.602518\tBest loss: 0.602518\tAccuracy: 80.67%\n",
      "17\tValidation loss: 0.704592\tBest loss: 0.602518\tAccuracy: 78.67%\n",
      "18\tValidation loss: 0.757420\tBest loss: 0.602518\tAccuracy: 77.33%\n",
      "19\tValidation loss: 0.652011\tBest loss: 0.602518\tAccuracy: 82.67%\n",
      "20\tValidation loss: 0.644286\tBest loss: 0.602518\tAccuracy: 81.33%\n",
      "21\tValidation loss: 0.681123\tBest loss: 0.602518\tAccuracy: 80.00%\n",
      "22\tValidation loss: 0.694311\tBest loss: 0.602518\tAccuracy: 79.33%\n",
      "23\tValidation loss: 0.689810\tBest loss: 0.602518\tAccuracy: 79.33%\n",
      "24\tValidation loss: 0.802399\tBest loss: 0.602518\tAccuracy: 78.67%\n",
      "25\tValidation loss: 0.804192\tBest loss: 0.602518\tAccuracy: 78.00%\n",
      "26\tValidation loss: 0.689533\tBest loss: 0.602518\tAccuracy: 79.33%\n",
      "27\tValidation loss: 0.637780\tBest loss: 0.602518\tAccuracy: 78.67%\n",
      "28\tValidation loss: 0.823339\tBest loss: 0.602518\tAccuracy: 76.67%\n",
      "29\tValidation loss: 0.683022\tBest loss: 0.602518\tAccuracy: 81.33%\n",
      "30\tValidation loss: 0.704697\tBest loss: 0.602518\tAccuracy: 81.33%\n",
      "31\tValidation loss: 0.666454\tBest loss: 0.602518\tAccuracy: 80.67%\n",
      "32\tValidation loss: 0.705740\tBest loss: 0.602518\tAccuracy: 78.67%\n",
      "33\tValidation loss: 0.734048\tBest loss: 0.602518\tAccuracy: 80.67%\n",
      "34\tValidation loss: 0.728781\tBest loss: 0.602518\tAccuracy: 79.33%\n",
      "35\tValidation loss: 0.720656\tBest loss: 0.602518\tAccuracy: 82.00%\n",
      "36\tValidation loss: 0.688744\tBest loss: 0.602518\tAccuracy: 81.33%\n",
      "Early stopping!\n",
      "Total training time: 0.8s\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n",
      "Final test accuracy: 76.49%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_best_mnist_model_0_to_4\")\n",
    "    t0 = time.time()\n",
    "    \n",
    "    hidden5_train = hidden5_out.eval(feed_dict={X: X_train2, y: y_train2})\n",
    "    hidden5_valid = hidden5_out.eval(feed_dict={X: X_valid2, y: y_valid2})\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            h5_batch, y_batch = hidden5_train[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={hidden5_out: h5_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={hidden5_out: hidden5_valid, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_outputs = 5\n",
    "\n",
    "restore_saver = tf.train.import_meta_graph(\"./my_best_mnist_model_0_to_4.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "hidden4_out = tf.get_default_graph().get_tensor_by_name(\"hidden4_out:0\")\n",
    "logits = tf.layers.dense(hidden4_out, n_outputs, kernel_initializer=he_init, name=\"new_logits\")\n",
    "Y_proba = tf.nn.softmax(logits)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"new_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "four_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_best_mnist_model_0_to_4\n",
      "0\tValidation loss: 0.819070\tBest loss: 0.819070\tAccuracy: 75.33%\n",
      "1\tValidation loss: 0.849165\tBest loss: 0.819070\tAccuracy: 76.67%\n",
      "2\tValidation loss: 0.685382\tBest loss: 0.685382\tAccuracy: 82.00%\n",
      "3\tValidation loss: 0.703680\tBest loss: 0.685382\tAccuracy: 81.33%\n",
      "4\tValidation loss: 0.718707\tBest loss: 0.685382\tAccuracy: 79.33%\n",
      "5\tValidation loss: 0.580858\tBest loss: 0.580858\tAccuracy: 84.67%\n",
      "6\tValidation loss: 0.696760\tBest loss: 0.580858\tAccuracy: 80.67%\n",
      "7\tValidation loss: 0.594550\tBest loss: 0.580858\tAccuracy: 83.33%\n",
      "8\tValidation loss: 0.610173\tBest loss: 0.580858\tAccuracy: 84.67%\n",
      "9\tValidation loss: 0.551225\tBest loss: 0.551225\tAccuracy: 84.67%\n",
      "10\tValidation loss: 0.611249\tBest loss: 0.551225\tAccuracy: 83.33%\n",
      "11\tValidation loss: 0.601020\tBest loss: 0.551225\tAccuracy: 83.33%\n",
      "12\tValidation loss: 0.604198\tBest loss: 0.551225\tAccuracy: 82.00%\n",
      "13\tValidation loss: 0.609906\tBest loss: 0.551225\tAccuracy: 80.67%\n",
      "14\tValidation loss: 0.588026\tBest loss: 0.551225\tAccuracy: 80.00%\n",
      "15\tValidation loss: 0.660723\tBest loss: 0.551225\tAccuracy: 82.00%\n",
      "16\tValidation loss: 0.652903\tBest loss: 0.551225\tAccuracy: 81.33%\n",
      "17\tValidation loss: 0.607171\tBest loss: 0.551225\tAccuracy: 84.00%\n",
      "18\tValidation loss: 0.604935\tBest loss: 0.551225\tAccuracy: 82.67%\n",
      "19\tValidation loss: 0.569622\tBest loss: 0.551225\tAccuracy: 82.00%\n",
      "20\tValidation loss: 0.544654\tBest loss: 0.544654\tAccuracy: 83.33%\n",
      "21\tValidation loss: 0.560229\tBest loss: 0.544654\tAccuracy: 84.00%\n",
      "22\tValidation loss: 0.532221\tBest loss: 0.532221\tAccuracy: 84.00%\n",
      "23\tValidation loss: 0.554571\tBest loss: 0.532221\tAccuracy: 82.67%\n",
      "24\tValidation loss: 0.619843\tBest loss: 0.532221\tAccuracy: 83.33%\n",
      "25\tValidation loss: 0.582212\tBest loss: 0.532221\tAccuracy: 82.67%\n",
      "26\tValidation loss: 0.522862\tBest loss: 0.522862\tAccuracy: 83.33%\n",
      "27\tValidation loss: 0.584412\tBest loss: 0.522862\tAccuracy: 83.33%\n",
      "28\tValidation loss: 0.574410\tBest loss: 0.522862\tAccuracy: 82.00%\n",
      "29\tValidation loss: 0.599742\tBest loss: 0.522862\tAccuracy: 83.33%\n",
      "30\tValidation loss: 0.599039\tBest loss: 0.522862\tAccuracy: 80.00%\n",
      "31\tValidation loss: 0.654844\tBest loss: 0.522862\tAccuracy: 80.67%\n",
      "32\tValidation loss: 0.620180\tBest loss: 0.522862\tAccuracy: 80.67%\n",
      "33\tValidation loss: 0.597123\tBest loss: 0.522862\tAccuracy: 82.00%\n",
      "34\tValidation loss: 0.604699\tBest loss: 0.522862\tAccuracy: 82.67%\n",
      "35\tValidation loss: 0.562791\tBest loss: 0.522862\tAccuracy: 82.00%\n",
      "36\tValidation loss: 0.620267\tBest loss: 0.522862\tAccuracy: 81.33%\n",
      "37\tValidation loss: 0.546574\tBest loss: 0.522862\tAccuracy: 84.00%\n",
      "38\tValidation loss: 0.535386\tBest loss: 0.522862\tAccuracy: 83.33%\n",
      "39\tValidation loss: 0.589947\tBest loss: 0.522862\tAccuracy: 82.67%\n",
      "40\tValidation loss: 0.557268\tBest loss: 0.522862\tAccuracy: 84.00%\n",
      "41\tValidation loss: 0.624974\tBest loss: 0.522862\tAccuracy: 82.67%\n",
      "42\tValidation loss: 0.616310\tBest loss: 0.522862\tAccuracy: 84.00%\n",
      "43\tValidation loss: 0.653370\tBest loss: 0.522862\tAccuracy: 81.33%\n",
      "44\tValidation loss: 0.526552\tBest loss: 0.522862\tAccuracy: 82.67%\n",
      "45\tValidation loss: 0.622420\tBest loss: 0.522862\tAccuracy: 82.67%\n",
      "46\tValidation loss: 0.522963\tBest loss: 0.522862\tAccuracy: 85.33%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_four_frozen\n",
      "Final test accuracy: 80.21%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_best_mnist_model_0_to_4\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = four_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_four_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    four_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_four_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "unfrozen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"hidden[34]|new_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam3\")\n",
    "training_op = optimizer.minimize(loss, var_list=unfrozen_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "two_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_four_frozen\n",
      "0\tValidation loss: 0.758216\tBest loss: 0.758216\tAccuracy: 80.00%\n",
      "1\tValidation loss: 0.425050\tBest loss: 0.425050\tAccuracy: 84.67%\n",
      "2\tValidation loss: 0.548179\tBest loss: 0.425050\tAccuracy: 86.00%\n",
      "3\tValidation loss: 0.451654\tBest loss: 0.425050\tAccuracy: 87.33%\n",
      "4\tValidation loss: 0.553614\tBest loss: 0.425050\tAccuracy: 84.00%\n",
      "5\tValidation loss: 0.636999\tBest loss: 0.425050\tAccuracy: 86.00%\n",
      "6\tValidation loss: 0.596471\tBest loss: 0.425050\tAccuracy: 86.67%\n",
      "7\tValidation loss: 0.494826\tBest loss: 0.425050\tAccuracy: 88.00%\n",
      "8\tValidation loss: 0.777300\tBest loss: 0.425050\tAccuracy: 87.33%\n",
      "9\tValidation loss: 1.114164\tBest loss: 0.425050\tAccuracy: 82.00%\n",
      "10\tValidation loss: 0.826468\tBest loss: 0.425050\tAccuracy: 83.33%\n",
      "11\tValidation loss: 0.690591\tBest loss: 0.425050\tAccuracy: 83.33%\n",
      "12\tValidation loss: 0.689556\tBest loss: 0.425050\tAccuracy: 86.67%\n",
      "13\tValidation loss: 0.703148\tBest loss: 0.425050\tAccuracy: 85.33%\n",
      "14\tValidation loss: 0.903634\tBest loss: 0.425050\tAccuracy: 80.00%\n",
      "15\tValidation loss: 0.460109\tBest loss: 0.425050\tAccuracy: 86.67%\n",
      "16\tValidation loss: 0.715585\tBest loss: 0.425050\tAccuracy: 88.00%\n",
      "17\tValidation loss: 0.640314\tBest loss: 0.425050\tAccuracy: 87.33%\n",
      "18\tValidation loss: 0.628331\tBest loss: 0.425050\tAccuracy: 88.00%\n",
      "19\tValidation loss: 0.817560\tBest loss: 0.425050\tAccuracy: 84.67%\n",
      "20\tValidation loss: 0.936013\tBest loss: 0.425050\tAccuracy: 86.67%\n",
      "21\tValidation loss: 1.039159\tBest loss: 0.425050\tAccuracy: 85.33%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_two_frozen\n",
      "Final test accuracy: 82.04%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    four_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_four_frozen\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = two_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_two_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    two_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_two_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam4\")\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "no_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_two_frozen\n",
      "0\tValidation loss: 1.616555\tBest loss: 1.616555\tAccuracy: 57.33%\n",
      "1\tValidation loss: 0.638685\tBest loss: 0.638685\tAccuracy: 83.33%\n",
      "2\tValidation loss: 1.005454\tBest loss: 0.638685\tAccuracy: 90.00%\n",
      "3\tValidation loss: 0.493598\tBest loss: 0.493598\tAccuracy: 83.33%\n",
      "4\tValidation loss: 0.735308\tBest loss: 0.493598\tAccuracy: 89.33%\n",
      "5\tValidation loss: 0.863948\tBest loss: 0.493598\tAccuracy: 88.00%\n",
      "6\tValidation loss: 0.916029\tBest loss: 0.493598\tAccuracy: 90.00%\n",
      "7\tValidation loss: 0.752270\tBest loss: 0.493598\tAccuracy: 88.00%\n",
      "8\tValidation loss: 1.768208\tBest loss: 0.493598\tAccuracy: 87.33%\n",
      "9\tValidation loss: 1.481399\tBest loss: 0.493598\tAccuracy: 92.67%\n",
      "10\tValidation loss: 1.929936\tBest loss: 0.493598\tAccuracy: 89.33%\n",
      "11\tValidation loss: 1.645900\tBest loss: 0.493598\tAccuracy: 90.67%\n",
      "12\tValidation loss: 2.263128\tBest loss: 0.493598\tAccuracy: 92.00%\n",
      "13\tValidation loss: 2.014274\tBest loss: 0.493598\tAccuracy: 91.33%\n",
      "14\tValidation loss: 0.528815\tBest loss: 0.493598\tAccuracy: 88.00%\n",
      "15\tValidation loss: 0.778924\tBest loss: 0.493598\tAccuracy: 86.67%\n",
      "16\tValidation loss: 0.844256\tBest loss: 0.493598\tAccuracy: 90.67%\n",
      "17\tValidation loss: 1.103011\tBest loss: 0.493598\tAccuracy: 92.00%\n",
      "18\tValidation loss: 0.913543\tBest loss: 0.493598\tAccuracy: 92.00%\n",
      "19\tValidation loss: 1.577488\tBest loss: 0.493598\tAccuracy: 91.33%\n",
      "20\tValidation loss: 1.726490\tBest loss: 0.493598\tAccuracy: 92.00%\n",
      "21\tValidation loss: 0.720458\tBest loss: 0.493598\tAccuracy: 92.67%\n",
      "22\tValidation loss: 1.617813\tBest loss: 0.493598\tAccuracy: 89.33%\n",
      "23\tValidation loss: 0.659995\tBest loss: 0.493598\tAccuracy: 92.00%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_no_frozen\n",
      "Final test accuracy: 79.26%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    two_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_two_frozen\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = no_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_no_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    no_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_no_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.674618\tBest loss: 0.674618\tAccuracy: 80.67%\n",
      "1\tValidation loss: 0.584845\tBest loss: 0.584845\tAccuracy: 88.67%\n",
      "2\tValidation loss: 0.647296\tBest loss: 0.584845\tAccuracy: 84.00%\n",
      "3\tValidation loss: 0.530389\tBest loss: 0.530389\tAccuracy: 87.33%\n",
      "4\tValidation loss: 0.683215\tBest loss: 0.530389\tAccuracy: 90.67%\n",
      "5\tValidation loss: 0.538040\tBest loss: 0.530389\tAccuracy: 89.33%\n",
      "6\tValidation loss: 0.670196\tBest loss: 0.530389\tAccuracy: 90.67%\n",
      "7\tValidation loss: 0.836470\tBest loss: 0.530389\tAccuracy: 85.33%\n",
      "8\tValidation loss: 0.837684\tBest loss: 0.530389\tAccuracy: 92.67%\n",
      "9\tValidation loss: 0.588950\tBest loss: 0.530389\tAccuracy: 88.00%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function elu at 0x11d853730>,\n",
       "       batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
       "       initializer=<tensorflow.python.ops.init_ops.VarianceScaling object at 0x112ea8fd0>,\n",
       "       learning_rate=0.01, n_hidden_layers=4, n_neurons=100,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf_5_to_9 = DNNClassifier(n_hidden_layers=4, random_state=42)\n",
    "dnn_clf_5_to_9.fit(X_train2, y_train2, n_epochs=1000, X_valid=X_valid2, y_valid=y_valid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8481793869574161"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf_5_to_9.predict(X_test2)\n",
    "accuracy_score(y_test2, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28 # MNIST\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, 2, n_inputs), name=\"X\")\n",
    "X1, X2 = tf.unstack(X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.int32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn1 = dnn(X1, name=\"DNN_A\")\n",
    "dnn2 = dnn(X2, name=\"DNN_B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_outputs = tf.concat([dnn1, dnn2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(100)])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(100)])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(200)])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = tf.layers.dense(dnn_outputs, units=10, activation=tf.nn.elu, kernel_initializer=he_init)\n",
    "logits = tf.layers.dense(hidden, units=1, kernel_initializer=he_init)\n",
    "y_proba = tf.nn.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.cast(tf.greater_equal(logits, 0), tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_as_float = tf.cast(y, tf.float32)\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_as_float, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.95\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_correct = tf.equal(y_pred, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(y_pred_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train\n",
    "y_train1 = y_train\n",
    "\n",
    "X_train2 = X_valid\n",
    "y_train2 = y_valid\n",
    "\n",
    "X_test = X_test\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(images, labels, batch_size):\n",
    "    size1 = batch_size // 2\n",
    "    size2 = batch_size - size1\n",
    "    if size1 != size2 and np.random.rand() > 0.5:\n",
    "        size1, size2 = size2, size1\n",
    "    X = []\n",
    "    y = []\n",
    "    while len(X) < size1:\n",
    "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
    "        if rnd_idx1 != rnd_idx2 and labels[rnd_idx1] == labels[rnd_idx2]:\n",
    "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
    "            y.append([1])\n",
    "    while len(X) < batch_size:\n",
    "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
    "        if labels[rnd_idx1] != labels[rnd_idx2]:\n",
    "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
    "            y.append([0])\n",
    "    rnd_indices = np.random.permutation(batch_size)\n",
    "    return np.array(X)[rnd_indices], np.array(y)[rnd_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "X_batch, y_batch = generate_batch(X_train1, y_train1, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 2, 784), dtype('float32'))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch.shape, X_batch.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18372a0390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3, 3 * batch_size))\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_batch[:,0].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(X_batch[:,1].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1, y_test1 = generate_batch(X_test, y_test, batch_size=len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train loss: 0.69103277\n",
      "0 Test accuracy: 0.542\n",
      "1 Train loss: 0.6035354\n",
      "2 Train loss: 0.54946035\n",
      "3 Train loss: 0.47047246\n",
      "4 Train loss: 0.4060757\n",
      "5 Train loss: 0.38308156\n",
      "5 Test accuracy: 0.824\n",
      "6 Train loss: 0.39047274\n",
      "7 Train loss: 0.3390794\n",
      "8 Train loss: 0.3210671\n",
      "9 Train loss: 0.31792685\n",
      "10 Train loss: 0.24494292\n",
      "10 Test accuracy: 0.8881\n",
      "11 Train loss: 0.2929235\n",
      "12 Train loss: 0.23225449\n",
      "13 Train loss: 0.23180929\n",
      "14 Train loss: 0.19877923\n",
      "15 Train loss: 0.20065464\n",
      "15 Test accuracy: 0.9203\n",
      "16 Train loss: 0.19700499\n",
      "17 Train loss: 0.18893136\n",
      "18 Train loss: 0.19965452\n",
      "19 Train loss: 0.24071647\n",
      "20 Train loss: 0.18882024\n",
      "20 Test accuracy: 0.9367\n",
      "21 Train loss: 0.12419197\n",
      "22 Train loss: 0.14013417\n",
      "23 Train loss: 0.120789476\n",
      "24 Train loss: 0.15721135\n",
      "25 Train loss: 0.11507861\n",
      "25 Test accuracy: 0.948\n",
      "26 Train loss: 0.13891116\n",
      "27 Train loss: 0.1526081\n",
      "28 Train loss: 0.123436704\n",
      "29 Train loss: 0.11543139\n",
      "30 Train loss: 0.1140282\n",
      "30 Test accuracy: 0.9507\n",
      "31 Train loss: 0.11897083\n",
      "32 Train loss: 0.09546645\n",
      "33 Train loss: 0.082996294\n",
      "34 Train loss: 0.13659164\n",
      "35 Train loss: 0.0680176\n",
      "35 Test accuracy: 0.9592\n",
      "36 Train loss: 0.11016853\n",
      "37 Train loss: 0.049499925\n",
      "38 Train loss: 0.081342936\n",
      "39 Train loss: 0.09441976\n",
      "40 Train loss: 0.08737087\n",
      "40 Test accuracy: 0.9619\n",
      "41 Train loss: 0.07678531\n",
      "42 Train loss: 0.065963484\n",
      "43 Train loss: 0.083247386\n",
      "44 Train loss: 0.07457435\n",
      "45 Train loss: 0.14071603\n",
      "45 Test accuracy: 0.9656\n",
      "46 Train loss: 0.067260325\n",
      "47 Train loss: 0.09936725\n",
      "48 Train loss: 0.049633194\n",
      "49 Train loss: 0.050840884\n",
      "50 Train loss: 0.04415762\n",
      "50 Test accuracy: 0.9685\n",
      "51 Train loss: 0.052975442\n",
      "52 Train loss: 0.04457429\n",
      "53 Train loss: 0.09052464\n",
      "54 Train loss: 0.09460125\n",
      "55 Train loss: 0.036653373\n",
      "55 Test accuracy: 0.9688\n",
      "56 Train loss: 0.046360612\n",
      "57 Train loss: 0.059152488\n",
      "58 Train loss: 0.0493788\n",
      "59 Train loss: 0.060345087\n",
      "60 Train loss: 0.041447375\n",
      "60 Test accuracy: 0.9733\n",
      "61 Train loss: 0.040578153\n",
      "62 Train loss: 0.057210773\n",
      "63 Train loss: 0.058645356\n",
      "64 Train loss: 0.042316362\n",
      "65 Train loss: 0.029543107\n",
      "65 Test accuracy: 0.9723\n",
      "66 Train loss: 0.05906513\n",
      "67 Train loss: 0.05033586\n",
      "68 Train loss: 0.045772236\n",
      "69 Train loss: 0.041796118\n",
      "70 Train loss: 0.04738202\n",
      "70 Test accuracy: 0.9743\n",
      "71 Train loss: 0.019732744\n",
      "72 Train loss: 0.039464083\n",
      "73 Train loss: 0.04187814\n",
      "74 Train loss: 0.05303406\n",
      "75 Train loss: 0.052625064\n",
      "75 Test accuracy: 0.9756\n",
      "76 Train loss: 0.038283084\n",
      "77 Train loss: 0.026332883\n",
      "78 Train loss: 0.07060841\n",
      "79 Train loss: 0.03239444\n",
      "80 Train loss: 0.03136283\n",
      "80 Test accuracy: 0.9731\n",
      "81 Train loss: 0.04390848\n",
      "82 Train loss: 0.015268046\n",
      "83 Train loss: 0.04875638\n",
      "84 Train loss: 0.029360933\n",
      "85 Train loss: 0.0418443\n",
      "85 Test accuracy: 0.9759\n",
      "86 Train loss: 0.018274888\n",
      "87 Train loss: 0.038872603\n",
      "88 Train loss: 0.02969683\n",
      "89 Train loss: 0.020990817\n",
      "90 Train loss: 0.045234833\n",
      "90 Test accuracy: 0.9769\n",
      "91 Train loss: 0.039237432\n",
      "92 Train loss: 0.031329047\n",
      "93 Train loss: 0.033414133\n",
      "94 Train loss: 0.025883088\n",
      "95 Train loss: 0.019567214\n",
      "95 Test accuracy: 0.9765\n",
      "96 Train loss: 0.020650322\n",
      "97 Train loss: 0.0339851\n",
      "98 Train loss: 0.047079965\n",
      "99 Train loss: 0.03125228\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 500\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(len(X_train1) // batch_size):\n",
    "            X_batch, y_batch = generate_batch(X_train1, y_train1, batch_size)\n",
    "            loss_val, _ = sess.run([loss, training_op], feed_dict={X: X_batch, y: y_batch})\n",
    "        print(epoch, \"Train loss:\", loss_val)\n",
    "        if epoch % 5 == 0:\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test1, y: y_test1})\n",
    "            print(epoch, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_digit_comparison_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "dnn_outputs = dnn(X, name=\"DNN_A\")\n",
    "frozen_outputs = tf.stop_gradient(dnn_outputs)\n",
    "\n",
    "logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init)\n",
    "Y_proba = tf.nn.softmax(logits)\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "dnn_A_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"DNN_A\")\n",
    "restore_saver = tf.train.Saver(var_list={var.op.name: var for var in dnn_A_vars})\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_digit_comparison_model.ckpt\n",
      "0 Test accuracy: 0.9455\n",
      "10 Test accuracy: 0.9634\n",
      "20 Test accuracy: 0.9659\n",
      "30 Test accuracy: 0.9656\n",
      "40 Test accuracy: 0.9655\n",
      "50 Test accuracy: 0.9656\n",
      "60 Test accuracy: 0.9655\n",
      "70 Test accuracy: 0.9656\n",
      "80 Test accuracy: 0.9654\n",
      "90 Test accuracy: 0.9654\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_digit_comparison_model.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 10 == 0:\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "            print(epoch, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_mnist_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "dnn_outputs = dnn(X, name=\"DNN_A\")\n",
    "\n",
    "logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init)\n",
    "Y_proba = tf.nn.softmax(logits)\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "dnn_A_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"DNN_A\")\n",
    "restore_saver = tf.train.Saver(var_list={var.op.name: var for var in dnn_A_vars})\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.8694\n",
      "10 Test accuracy: 0.9276\n",
      "20 Test accuracy: 0.9299\n",
      "30 Test accuracy: 0.935\n",
      "40 Test accuracy: 0.942\n",
      "50 Test accuracy: 0.9435\n",
      "60 Test accuracy: 0.9442\n",
      "70 Test accuracy: 0.9447\n",
      "80 Test accuracy: 0.9448\n",
      "90 Test accuracy: 0.945\n",
      "100 Test accuracy: 0.945\n",
      "110 Test accuracy: 0.9458\n",
      "120 Test accuracy: 0.9456\n",
      "130 Test accuracy: 0.9458\n",
      "140 Test accuracy: 0.9458\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 150\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 10 == 0:\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "            print(epoch, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_mnist_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
